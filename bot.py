#!/usr/bin/env python3
"""
Konspekt Helper Bot - –£–º–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º
–ë–æ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ–ª–µ–∑–Ω—ã–µ –∫–æ–Ω—Å–ø–µ–∫—Ç—ã
"""

import os
import logging
import json
import requests
from datetime import datetime
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading
import random
import re
import html

# ==================== –ù–ê–°–¢–†–û–ô–ö–ê ====================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID", "13aac457275834df9")
RENDER_EXTERNAL_URL = os.getenv("RENDER_EXTERNAL_URL", "")
PORT = int(os.getenv("PORT", 10000))

if not TELEGRAM_TOKEN:
    logger.error("‚ùå TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    exit(1)

# ==================== –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================
stats = {
    "total_users": 0,
    "total_messages": 0,
    "conspects_created": 0,
    "google_searches": 0,
    "start_time": datetime.now().isoformat(),
    "user_states": {}
}

# ==================== –£–ú–ù–´–ô –ê–ù–ê–õ–ò–ó–ê–¢–û–† –ò–ù–§–û–†–ú–ê–¶–ò–ò ====================
class InformationAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
    
    def analyze_topic(self, query, search_results):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–º—É –∏ —Å–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–µ–º—ã
        topic_type = self._determine_topic_type(query)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        analysis = self._analyze_search_results(search_results, query)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç
        structured_info = self._create_structured_info(query, topic_type, analysis)
        
        return structured_info
    
    def _determine_topic_type(self, query):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–µ–º—ã"""
        query_lower = query.lower()
        
        topic_types = {
            "–Ω–∞—É—á–Ω–∞—è_—Ç–µ–º–∞": ["–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç", "—Ç–µ–æ—Ä–∏—è", "–Ω–∞—É–∫–∞", "—É—á–µ–Ω—ã–π", "–æ—Ç–∫—Ä—ã—Ç–∏–µ"],
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": ["—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "—Ä–æ–±–æ—Ç", "–∫–æ–º–ø—å—é—Ç–µ—Ä"],
            "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": ["–∏—Å—Ç–æ—Ä–∏—è", "–≤–æ–π–Ω–∞", "—Ä–µ–≤–æ–ª—é—Ü–∏—è", "–¥—Ä–µ–≤–Ω–∏–π", "—Å—Ä–µ–¥–Ω–µ–≤–µ–∫–æ–≤—å–µ"],
            "—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": ["—ç–∫–æ–Ω–æ–º–∏–∫–∞", "—Ñ–∏–Ω–∞–Ω—Å—ã", "—Ä—ã–Ω–æ–∫", "–±–∏–∑–Ω–µ—Å", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–∫—Ä–∏–∑–∏—Å"],
            "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_—Ç–µ–º–∞": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "–æ–±—É—á–µ–Ω–∏–µ", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç", "—à–∫–æ–ª–∞", "—Å—Ç—É–¥–µ–Ω—Ç"],
            "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è_—Ç–µ–º–∞": ["–º–µ–¥–∏—Ü–∏–Ω–∞", "–∑–¥–æ—Ä–æ–≤—å–µ", "–±–æ–ª–µ–∑–Ω—å", "–ª–µ—á–µ–Ω–∏–µ", "–≤—Ä–∞—á", "–≤–∞–∫—Ü–∏–Ω–∞"],
            "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è_—Ç–µ–º–∞": ["–æ–±—â–µ—Å—Ç–≤–æ", "–∫—É–ª—å—Ç—É—Ä–∞", "–ø–æ–ª–∏—Ç–∏–∫–∞", "–ø—Ä–∞–≤–∞", "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π", "—ç—Ç–∏–∫–∞"]
        }
        
        for topic_type, keywords in topic_types.items():
            for keyword in keywords:
                if keyword in query_lower:
                    return topic_type
        
        return "–æ–±—â–∞—è_—Ç–µ–º–∞"
    
    def _analyze_search_results(self, results, query):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞"""
        items = results.get("items", [])
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        all_text = ""
        key_points = []
        statistics = []
        definitions = []
        
        for item in items[:5]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            text = item.get("snippet", "")
            all_text += text + " "
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
            if len(text) > 50:
                # –ò—â–µ–º —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                sentences = re.split(r'[.!?]+', text)
                for sentence in sentences:
                    sentence = sentence.strip()
                    if 30 < len(sentence) < 150:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                        if self._is_useful_sentence(sentence, query):
                            key_points.append(sentence[:120] + "...")
            
            # –ò—â–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ —Ü–∏—Ñ—Ä—ã
            numbers = re.findall(r'\d+[%‚Ä∞¬∞]|\d+\.\d+', text)
            if numbers:
                statistics.extend(numbers)
            
            # –ò—â–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            if " ‚Äî —ç—Ç–æ " in text or " —è–≤–ª—è–µ—Ç—Å—è " in text or " –æ–∑–Ω–∞—á–∞–µ—Ç " in text:
                definitions.append(text[:100] + "...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        key_terms = self._extract_key_terms(all_text, query)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã
        aspects = self._identify_aspects(all_text, query)
        
        return {
            "key_points": list(set(key_points))[:8],  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
            "statistics": list(set(statistics))[:5],
            "definitions": list(set(definitions))[:3],
            "key_terms": key_terms[:10],
            "aspects": aspects[:5],
            "total_sources": len(items),
            "main_findings": self._summarize_findings(key_points, query)
        }
    
    def _is_useful_sentence(self, sentence, query):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–ª–µ–∑–Ω—ã–º"""
        sentence_lower = sentence.lower()
        query_words = query.lower().split()
        
        # –ù–µ –ø–æ–ª–µ–∑–Ω–æ, –µ—Å–ª–∏:
        # 1. –≠—Ç–æ –≤–æ–ø—Ä–æ—Å
        if '?' in sentence:
            return False
        
        # 2. –°–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–æ–≤–∞-—Ñ–∏–ª–ª–µ—Ä—ã
        fillers = ["click here", "read more", "learn more", "continue reading", 
                  "–ø–æ–¥—Ä–æ–±–Ω–µ–µ", "—á–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ", "—É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ"]
        if any(filler in sentence_lower for filler in fillers):
            return False
        
        # 3. –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        if len(sentence) < 20 or len(sentence) > 200:
            return False
        
        # 4. –°–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∑–∞–ø—Ä–æ—Å–∞ (—ç—Ç–æ —Ö–æ—Ä–æ—à–æ!)
        relevant_words = sum(1 for word in query_words if len(word) > 3 and word in sentence_lower)
        
        return relevant_words > 0 or len(sentence.split()) > 5
    
    def _extract_key_terms(self, text, query):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã"""
        stop_words = {
            "–∏", "–≤", "–Ω–∞", "—Å", "–ø–æ", "–æ", "–æ–±", "–¥–ª—è", "–∏–∑", "–æ—Ç", "—ç—Ç–æ",
            "—á—Ç–æ", "–∫–∞–∫", "–Ω–æ", "–∞", "–∏–ª–∏", "–µ—Å–ª–∏", "—Ç–æ", "–∂–µ", "–±—ã", "–ª–∏"
        }
        
        # –ù–∞—Ö–æ–¥–∏–º —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ (—Å–ª–æ–≤–∞ –æ—Ç 4 –±—É–∫–≤)
        words = re.findall(r'\b[–∞-—è—ë]{4,}\b', text.lower())
        
        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
        word_freq = {}
        for word in words:
            if word not in stop_words:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
        sorted_terms = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [term.capitalize() for term, freq in sorted_terms[:15]]
    
    def _identify_aspects(self, text, query):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã"""
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–º
        aspect_templates = {
            "–Ω–∞—É—á–Ω–∞—è_—Ç–µ–º–∞": [
                "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã",
                "–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ",
                "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≤–æ–¥—ã",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
                "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è"
            ],
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": [
                "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã",
                "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã",
                "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏",
                "–û–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
                "–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è",
                "–ë—É–¥—É—â–∏–µ —Ç—Ä–µ–Ω–¥—ã"
            ],
            "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": [
                "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç",
                "–ö–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è",
                "–£—á–∞—Å—Ç–Ω–∏–∫–∏ –∏ –ª–∏—á–Ω–æ—Å—Ç–∏",
                "–ü—Ä–∏—á–∏–Ω—ã –∏ –ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏",
                "–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –∏ –≤–ª–∏—è–Ω–∏–µ",
                "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è"
            ],
            "—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": [
                "–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è",
                "–†—ã–Ω–æ—á–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã",
                "–§–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è–Ω–∏—è",
                "–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Ä–∞–∑–≤–∏—Ç–∏—è",
                "–ü—Ä–æ–±–ª–µ–º—ã –∏ –≤—ã–∑–æ–≤—ã",
                "–ü—Ä–æ–≥–Ω–æ–∑—ã –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏"
            ],
            "–æ–±—â–∞—è_—Ç–µ–º–∞": [
                "–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è",
                "–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
                "–ó–Ω–∞—á–µ–Ω–∏–µ –∏ –≤–∞–∂–Ω–æ—Å—Ç—å",
                "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
                "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ"
            ]
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–µ–º—ã
        topic_type = self._determine_topic_type(query)
        aspects = aspect_templates.get(topic_type, aspect_templates["–æ–±—â–∞—è_—Ç–µ–º–∞"])
        
        return aspects
    
    def _summarize_findings(self, key_points, query):
        """–°—É–º–º–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏"""
        if not key_points:
            return [f"–¢–µ–º–∞ '{query}' —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è."]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–æ—á–∫–∏
        grouped = []
        for point in key_points[:5]:
            # –£–ø—Ä–æ—â–∞–µ–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º
            simplified = self._simplify_point(point)
            if simplified and simplified not in grouped:
                grouped.append(simplified)
        
        return grouped[:4]
    
    def _simplify_point(self, point):
        """–£–ø—Ä–æ—â–∞–µ—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—É—é —Ç–æ—á–∫—É"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ
        point = re.sub(r'\s+', ' ', point).strip()
        
        # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è, —Å–æ–∫—Ä–∞—â–∞–µ–º
        if len(point) > 80:
            # –ë–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü
            words = point.split()
            if len(words) > 12:
                point = ' '.join(words[:10]) + '...'
        
        return point
    
    def _create_structured_info(self, query, topic_type, analysis):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        return {
            "topic": query,
            "type": topic_type,
            "analysis": analysis,
            "recommendations": self._generate_recommendations(topic_type, analysis),
            "study_plan": self._create_study_plan(topic_type),
            "timestamp": datetime.now().isoformat()
        }
    
    def _generate_recommendations(self, topic_type, analysis):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–∑—É—á–µ–Ω–∏—é"""
        recommendations = [
            "–ò–∑—É—á–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è",
            "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –ø–æ–Ω—è—Ç–∏—è",
            "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–µ–º—É —Å —Ä–∞–∑–Ω—ã—Ö —Ç–æ—á–µ–∫ –∑—Ä–µ–Ω–∏—è",
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
            "–°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –∏–∑—É—á–µ–Ω–∏—é —Ç–µ–º—ã"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if topic_type == "–Ω–∞—É—á–Ω–∞—è_—Ç–µ–º–∞":
            recommendations.extend([
                "–û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º–∏",
                "–ò–∑—É—á–∏—Ç–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç",
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π"
            ])
        elif topic_type == "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞":
            recommendations.extend([
                "–ò–∑—É—á–∏—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è"
            ])
        
        return recommendations[:6]
    
    def _create_study_plan(self, topic_type):
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è —Ç–µ–º—ã"""
        plans = {
            "–Ω–∞—É—á–Ω–∞—è_—Ç–µ–º–∞": [
                "1. –ò–∑—É—á–∏—Ç–µ –±–∞–∑–æ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è",
                "2. –û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –∏—Å—Ç–æ—Ä–∏–µ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ç–µ–º—ã",
                "3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Ä–∞–±–æ—Ç—ã –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏",
                "4. –ò–∑—É—á–∏—Ç–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏",
                "5. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ"
            ],
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è_—Ç–µ–º–∞": [
                "1. –ü–æ–π–º–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã",
                "2. –ò–∑—É—á–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã",
                "3. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
                "4. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è",
                "5. –ò–∑—É—á–∏—Ç–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è"
            ],
            "–æ–±—â–∞—è_—Ç–µ–º–∞": [
                "1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è",
                "2. –ò–∑—É—á–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã",
                "3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è",
                "4. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ",
                "5. –ò–∑—É—á–∏—Ç–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Ä–∞–∑–≤–∏—Ç–∏—è"
            ]
        }
        
        return plans.get(topic_type, plans["–æ–±—â–∞—è_—Ç–µ–º–∞"])

# ==================== –£–ú–ù–´–ô –ü–û–ò–°–ö ====================
class SmartGoogleSearch:
    def __init__(self):
        self.api_key = GOOGLE_API_KEY
        self.cse_id = GOOGLE_CSE_ID
        self.base_url = "https://www.googleapis.com/customsearch/v1"
        self.analyzer = InformationAnalyzer()
        
    def search_and_analyze(self, query):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        if not query or len(query.strip()) < 2:
            return {"error": "–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å"}
        
        stats["google_searches"] += 1
        
        params = {
            "key": self.api_key,
            "cx": self.cse_id,
            "q": query,
            "num": 7,  # –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            "hl": "ru",
            "lr": "lang_ru",
            "gl": "ru"
        }
        
        try:
            response = requests.get(self.base_url, params=params, timeout=15)
            
            if response.status_code != 200:
                return self._create_smart_fallback(query)
            
            data = response.json()
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            structured_info = self.analyzer.analyze_topic(query, data)
            
            return {
                "success": True,
                "query": query,
                "structured_info": structured_info,
                "raw_results": data.get("items", []),
                "search_info": data.get("searchInformation", {}),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return self._create_smart_fallback(query)
    
    def _create_smart_fallback(self, query):
        """–°–æ–∑–¥–∞–µ—Ç —É–º–Ω—ã–π fallback —Å –∞–Ω–∞–ª–∏–∑–æ–º"""
        analyzer = InformationAnalyzer()
        topic_type = analyzer._determine_topic_type(query)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–∞–∂–µ –±–µ–∑ –ø–æ–∏—Å–∫–∞
        fake_analysis = {
            "key_points": [
                f"–¢–µ–º–∞ '{query}' —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω–æ–π –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è",
                "–°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –¥–∞–Ω–Ω–æ–π —Ç–µ–º—ã",
                "–î–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"
            ],
            "statistics": [],
            "definitions": [f"{query} ‚Äî –≤–∞–∂–Ω–æ–µ –ø–æ–Ω—è—Ç–∏–µ, —Ç—Ä–µ–±—É—é—â–µ–µ –∏–∑—É—á–µ–Ω–∏—è"],
            "key_terms": [query.capitalize(), "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "–ê–Ω–∞–ª–∏–∑", "–ò–∑—É—á–µ–Ω–∏–µ"],
            "aspects": analyzer._identify_aspects("", query),
            "total_sources": 0,
            "main_findings": [f"–¢–µ–º–∞ '{query}' —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"]
        }
        
        structured_info = analyzer._create_structured_info(query, topic_type, fake_analysis)
        
        return {
            "success": False,
            "query": query,
            "structured_info": structured_info,
            "fallback": True,
            "timestamp": datetime.now().isoformat()
        }

# ==================== –£–ú–ù–´–ô –ì–ï–ù–ï–†–ê–¢–û–† –ö–û–ù–°–ü–ï–ö–¢–û–í ====================
class SmartConspectGenerator:
    def __init__(self):
        self.searcher = SmartGoogleSearch()
        logger.info("‚úÖ –£–º–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ –≥–æ—Ç–æ–≤")
    
    def generate(self, topic, volume="short"):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–º–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        # –ü–∞—Å—Ö–∞–ª–∫–∞
        if self._is_easter_egg(topic):
            return self._create_easter_egg_response()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑
        search_results = self.searcher.search_and_analyze(topic)
        structured_info = search_results.get("structured_info", {})
        analysis = structured_info.get("analysis", {})
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞
        if volume == "detailed":
            return self._generate_detailed(topic, structured_info, analysis)
        elif volume == "extended":
            return self._generate_extended(topic, structured_info, analysis)
        else:
            return self._generate_short(topic, structured_info, analysis)
    
    def _is_easter_egg(self, text):
        text_lower = text.lower()
        return any(phrase in text_lower for phrase in [
            "–ø–ª–∞–Ω –∑–∞—Ö–≤–∞—Ç–∞ –ø–æ–ª—å—à–∏", "–∑–∞—Ö–≤–∞—Ç –ø–æ–ª—å—à–∏", "—á–∞–π–Ω–∞—è –ø–∞—Å—Ö–∞–ª–∫–∞"
        ])
    
    def _create_easter_egg_response(self):
        responses = [
            "üçµ *–°–µ–∫—Ä–µ—Ç–Ω–∞—è –ø–∞—Å—Ö–∞–ª–∫–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞!*\n\n–ê–Ω–∞–ª–∏–∑: –ß–∞–π–Ω–∞—è —Ü–µ—Ä–µ–º–æ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω—ã–º –∫—É–ª—å—Ç—É—Ä–Ω—ã–º —Ñ–µ–Ω–æ–º–µ–Ω–æ–º. –§–æ–∫—Å—è –≤ –ø—É—Ç–∏ —Å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º –æ—Ç—á–µ—Ç–æ–º...",
            "üçµ *Easter Egg Analyzed!*\n\nTea ceremony analysis complete. Foksya delivering structured report..."
        ]
        return random.choice(responses)
    
    def _generate_short(self, topic, structured_info, analysis):
        """–ö—Ä–∞—Ç–∫–∏–π —É–º–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        conspect = f"üß† *–ê–ù–ê–õ–ò–ó: {topic.upper()}*\n\n"
        
        # –¢–∏–ø —Ç–µ–º—ã
        topic_type = structured_info.get("type", "–æ–±—â–∞—è_—Ç–µ–º–∞").replace("_", " ").title()
        conspect += f"üìä *–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:* {topic_type}\n"
        conspect += f"üîç *–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:* {analysis.get('total_sources', 0)}\n\n"
        
        # –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã
        conspect += "üéØ *–ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´:*\n\n"
        
        findings = analysis.get("main_findings", [])
        if findings:
            for i, finding in enumerate(findings[:3], 1):
                conspect += f"{i}. {finding}\n"
        else:
            conspect += "1. –¢–µ–º–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–µ—Å\n"
            conspect += "2. –¢—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è\n"
            conspect += "3. –ò–º–µ–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å\n"
        
        # –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        conspect += f"\nüîë *–ö–õ–Æ–ß–ï–í–´–ï –¢–ï–†–ú–ò–ù–´:*\n"
        terms = analysis.get("key_terms", [])
        if terms:
            for term in terms[:5]:
                conspect += f"‚Ä¢ {term}\n"
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        conspect += f"\nüí° *–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:*\n"
        recs = structured_info.get("recommendations", [])
        if recs:
            conspect += f"{recs[0]}\n"
        else:
            conspect += "–ò–∑—É—á–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è.\n"
        
        conspect += f"\nü§ñ *@Konspekt_help_bot* | üß† *–£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑*"
        
        return conspect
    
    def _generate_detailed(self, topic, structured_info, analysis):
        """–ü–æ–¥—Ä–æ–±–Ω—ã–π —É–º–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        conspect = f"üìö *–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: {topic.upper()}*\n\n"
        
        # –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üî¨ *–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –ê–ù–ê–õ–ò–ó–ê*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        topic_type = structured_info.get("type", "–æ–±—â–∞—è_—Ç–µ–º–∞").replace("_", " ").title()
        
        conspect += f"*–¢–µ–º–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:* {topic}\n"
        conspect += f"*–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:* {topic_type}\n"
        conspect += f"*–û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö:* {analysis.get('total_sources', 0)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
        conspect += f"*–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞:* {datetime.now().strftime('%H:%M')}\n\n"
        
        # –ö–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üìä *–ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ï –í–´–í–û–î–´*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        key_points = analysis.get("key_points", [])
        if key_points:
            conspect += "*–û–°–ù–û–í–ù–´–ï –ù–ê–•–û–î–ö–ò:*\n\n"
            for i, point in enumerate(key_points[:5], 1):
                conspect += f"{i}. {point}\n\n"
        else:
            conspect += "*–ê–ù–ê–õ–ò–ó –ü–û–ö–ê–ó–ê–õ:*\n\n"
            conspect += "1. –¢–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è\n"
            conspect += "2. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è\n"
            conspect += "3. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏\n\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –¥–∞–Ω–Ω—ã–µ
        statistics = analysis.get("statistics", [])
        if statistics:
            conspect += "*–¶–ò–§–†–´ –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê:*\n"
            for stat in statistics[:3]:
                conspect += f"‚Ä¢ {stat}\n"
            conspect += "\n"
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ–º—ã
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üèó *–°–¢–†–£–ö–¢–£–†–ê –¢–ï–ú–´*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        aspects = analysis.get("aspects", [])
        if aspects:
            conspect += "*–ö–õ–Æ–ß–ï–í–´–ï –ê–°–ü–ï–ö–¢–´ –î–õ–Ø –ò–ó–£–ß–ï–ù–ò–Ø:*\n\n"
            for i, aspect in enumerate(aspects[:5], 1):
                conspect += f"{i}. **{aspect}**\n"
                conspect += f"   –î–∞–Ω–Ω—ã–π –∞—Å–ø–µ–∫—Ç —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω—ã–º –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã.\n\n"
        else:
            conspect += "*–†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø –ò–ó–£–ß–ï–ù–ò–Ø:*\n\n"
            directions = [
                "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
                "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ",
                "–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã",
                "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –æ—Ü–µ–Ω–∫–∞"
            ]
            for i, direction in enumerate(directions, 1):
                conspect += f"{i}. {direction}\n"
            conspect += "\n"
        
        # –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
        conspect += "*–¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ü–ü–ê–†–ê–¢:*\n"
        terms = analysis.get("key_terms", [])
        if terms:
            for term in terms[:8]:
                conspect += f"‚Ä¢ **{term}** ‚Äî –∫–ª—é—á–µ–≤–æ–µ –ø–æ–Ω—è—Ç–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–µ–º—ã\n"
        conspect += "\n"
        
        # –ò—Ç–æ–≥–∏
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üíé *–ò–¢–û–ì–ò –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        conspect += "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –≤—ã–≤–æ–¥—ã:\n\n"
        
        conclusions = [
            "–¢–µ–º–∞ –æ–±–ª–∞–¥–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–∑—É—á–µ–Ω–∏—è",
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Å–º—ã—Å–ª–µ–Ω–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏",
            "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã",
            "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Ç–µ–º—ã"
        ]
        
        for i, conclusion in enumerate(conclusions, 1):
            conspect += f"{i}. {conclusion}\n"
        
        # –ü–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è
        conspect += f"\nüìã *–ü–õ–ê–ù –ò–ó–£–ß–ï–ù–ò–Ø –¢–ï–ú–´:*\n\n"
        study_plan = structured_info.get("study_plan", [])
        for step in study_plan[:3]:
            conspect += f"{step}\n"
        
        conspect += f"\nüîç *–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —É–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏*\n"
        conspect += f"ü§ñ *@Konspekt_help_bot* | üß† *–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥*"
        
        return conspect
    
    def _generate_extended(self, topic, structured_info, analysis):
        """–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π —É–º–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        conspect = f"üìñ *–ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï: {topic.upper()}*\n\n"
        
        # –ß–∞—Å—Ç—å 1: –í–≤–µ–¥–µ–Ω–∏–µ –∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
        conspect += "=" * 60 + "\n"
        conspect += "–ß–ê–°–¢–¨ 1: –í–í–ï–î–ï–ù–ò–ï –ò –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø\n"
        conspect += "=" * 60 + "\n\n"
        
        topic_type = structured_info.get("type", "–æ–±—â–∞—è_—Ç–µ–º–∞").replace("_", " ").title()
        
        conspect += f"**–ù–ê–ó–í–ê–ù–ò–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:** –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä —Ç–µ–º—ã ¬´{topic}¬ª\n\n"
        
        conspect += "**–¶–ï–õ–¨ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n"
        conspect += "–ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è "
        conspect += "–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Ç–µ–º—ã.\n\n"
        
        conspect += "**–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø:**\n"
        conspect += "1. –°–±–æ—Ä –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
        conspect += "2. –ê–Ω–∞–ª–∏–∑ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n"
        conspect += "3. –í—ã–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤\n"
        conspect += "4. –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ –ø–ª–∞–Ω–∞ –∏–∑—É—á–µ–Ω–∏—è\n"
        conspect += "5. –§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–æ–≤ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤\n\n"
        
        conspect += f"**–¢–ò–ü –¢–ï–ú–´:** {topic_type}\n"
        conspect += f"**–û–ë–™–ï–ú –î–ê–ù–ù–´–•:** {analysis.get('total_sources', 0)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
        conspect += f"**–í–†–ï–ú–Ø –ü–†–û–í–ï–î–ï–ù–ò–Ø:** {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n"
        
        # –ß–∞—Å—Ç—å 2: –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä
        conspect += "=" * 60 + "\n"
        conspect += "–ß–ê–°–¢–¨ 2: –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –û–ë–ó–û–† –ò–ù–§–û–†–ú–ê–¶–ò–ò\n"
        conspect += "=" * 60 + "\n\n"
        
        conspect += "**–ê–ù–ê–õ–ò–ó –î–û–°–¢–£–ü–ù–´–• –î–ê–ù–ù–´–•:**\n\n"
        
        key_points = analysis.get("key_points", [])
        if key_points:
            conspect += "*–û–°–ù–û–í–ù–´–ï –ù–ê–•–û–î–ö–ò –ò–ó –ò–°–¢–û–ß–ù–ò–ö–û–í:*\n\n"
            for i, point in enumerate(key_points[:6], 1):
                conspect += f"{i}. {point}\n\n"
        else:
            conspect += "–ü—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ —Ç–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –∫ –∏–∑—É—á–µ–Ω–∏—é. "
            conspect += "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –∏ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è "
            conspect += "–ø–æ–ª–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ –ø—Ä–µ–¥–º–µ—Ç–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n\n"
        
        # –î–∞–Ω–Ω—ã–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        statistics = analysis.get("statistics", [])
        definitions = analysis.get("definitions", [])
        
        if statistics:
            conspect += "*–¶–ò–§–†–û–í–´–ï –î–ê–ù–ù–´–ï –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê:*\n"
            for stat in statistics:
                conspect += f"‚Ä¢ {stat}\n"
            conspect += "\n"
        
        if definitions:
            conspect += "*–û–°–ù–û–í–ù–´–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø:*\n"
            for definition in definitions:
                conspect += f"‚Ä¢ {definition}\n"
            conspect += "\n"
        
        # –ß–∞—Å—Ç—å 3: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        conspect += "=" * 60 + "\n"
        conspect += "–ß–ê–°–¢–¨ 3: –°–¢–†–£–ö–¢–£–†–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–ï–ú–´\n"
        conspect += "=" * 60 + "\n\n"
        
        conspect += "**–°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ò–ï –ó–ù–ê–ù–ò–ô:**\n\n"
        
        aspects = analysis.get("aspects", [])
        if aspects:
            conspect += "*–ö–õ–Æ–ß–ï–í–´–ï –ê–°–ü–ï–ö–¢–´ –¢–ï–ú–´ –î–õ–Ø –£–ì–õ–£–ë–õ–ï–ù–ù–û–ì–û –ò–ó–£–ß–ï–ù–ò–Ø:*\n\n"
            
            for i, aspect in enumerate(aspects, 1):
                conspect += f"**{i}. {aspect}**\n"
                conspect += "   –î–∞–Ω–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω—ã–º –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è "
                conspect += "–∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–¥–µ–ª–∏—Ç—å –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ "
                conspect += "–∏–∑—É—á–µ–Ω–∏—é –¥–∞–Ω–Ω–æ–≥–æ –∞—Å–ø–µ–∫—Ç–∞, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—è –µ–≥–æ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö "
                conspect += "–∏ —Å —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø–æ–∑–∏—Ü–∏–π.\n\n"
        else:
            conspect += "*–†–ï–ö–û–ú–ï–ù–î–£–ï–ú–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ò–ó–£–ß–ï–ù–ò–Ø:*\n\n"
            structure = [
                "–§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –æ—Å–Ω–æ–≤—ã –∏ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è",
                "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ —ç–≤–æ–ª—é—Ü–∏—è –ø–æ–Ω—è—Ç–∏–π",
                "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è",
                "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –æ—Ü–µ–Ω–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤"
            ]
            for i, item in enumerate(structure, 1):
                conspect += f"{i}. {item}\n\n"
        
        # –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
        conspect += "**–¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ü–ü–ê–†–ê–¢ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n\n"
        
        terms = analysis.get("key_terms", [])
        if terms:
            for i, term in enumerate(terms[:12], 1):
                conspect += f"{i}. **{term}** ‚Äî –∫–ª—é—á–µ–≤–æ–µ –ø–æ–Ω—è—Ç–∏–µ, —Ç—Ä–µ–±—É—é—â–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è "
                conspect += "–≤ —Ä–∞–º–∫–∞—Ö –∏–∑—É—á–µ–Ω–∏—è —Ç–µ–º—ã. –ü–æ–Ω–∏–º–∞–Ω–∏–µ –¥–∞–Ω–Ω–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞ —è–≤–ª—è–µ—Ç—Å—è "
                conspect += "–≤–∞–∂–Ω—ã–º –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è.\n\n"
        else:
            conspect += "–î–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Ç–µ–º—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Å–≤–æ–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é "
            conspect += "—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏ –ø–æ–Ω—è—Ç–∏–π–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞—Ä—å "
            conspect += "–∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏–∑—É—á–µ–Ω–∏—è.\n\n"
        
        # –ß–∞—Å—Ç—å 4: –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        conspect += "=" * 60 + "\n"
        conspect += "–ß–ê–°–¢–¨ 4: –ú–ï–¢–û–î–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –ü–õ–ê–ù –ò–ó–£–ß–ï–ù–ò–Ø\n"
        conspect += "=" * 60 + "\n\n"
        
        conspect += "**–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –°–ò–°–¢–ï–ú–ê–¢–ò–ß–ï–°–ö–û–ú–£ –ò–ó–£–ß–ï–ù–ò–Æ:**\n\n"
        
        recommendations = structured_info.get("recommendations", [])
        if recommendations:
            for i, recommendation in enumerate(recommendations, 1):
                conspect += f"{i}. {recommendation}\n"
            conspect += "\n"
        else:
            recs = [
                "–ù–∞—á–Ω–∏—Ç–µ —Å –∏–∑—É—á–µ–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏–π –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π",
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
                "–í–µ–¥–∏—Ç–µ –∫–æ–Ω—Å–ø–µ–∫—Ç—ã –∏ –≤—ã–ø–∏—Å—ã–≤–∞–π—Ç–µ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã",
                "–û–±—Å—É–∂–¥–∞–π—Ç–µ —Ç–µ–º—É —Å –¥—Ä—É–≥–∏–º–∏ –¥–ª—è –æ–±–º–µ–Ω–∞ –º–Ω–µ–Ω–∏—è–º–∏",
                "–†–µ–≥—É–ª—è—Ä–Ω–æ –ø–æ–≤—Ç–æ—Ä—è–π—Ç–µ –∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∏—Ä—É–π—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è"
            ]
            for i, rec in enumerate(recs, 1):
                conspect += f"{i}. {rec}\n"
            conspect += "\n"
        
        conspect += "**–ü–û–®–ê–ì–û–í–´–ô –ü–õ–ê–ù –ò–ó–£–ß–ï–ù–ò–Ø –¢–ï–ú–´:**\n\n"
        
        study_plan = structured_info.get("study_plan", [])
        for step in study_plan:
            conspect += f"{step}\n"
        conspect += "\n"
        
        conspect += "**–†–ï–°–£–†–°–´ –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ï–ì–û –ò–ó–£–ß–ï–ù–ò–Ø:**\n"
        conspect += "‚Ä¢ –ù–∞—É—á–Ω—ã–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n"
        conspect += "‚Ä¢ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞\n"
        conspect += "‚Ä¢ –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –∫—É—Ä—Å—ã –∏ –ª–µ–∫—Ü–∏–∏\n"
        conspect += "‚Ä¢ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –∏ —Ñ–æ—Ä—É–º—ã\n"
        conspect += "‚Ä¢ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∫–µ–π—Å—ã –∏ –ø—Ä–∏–º–µ—Ä—ã\n\n"
        
        # –ß–∞—Å—Ç—å 5: –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
        conspect += "=" * 60 + "\n"
        conspect += "–ß–ê–°–¢–¨ 5: –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –ò –ü–ï–†–°–ü–ï–ö–¢–ò–í–´\n"
        conspect += "=" * 60 + "\n\n"
        
        conspect += "**–û–°–ù–û–í–ù–´–ï –í–´–í–û–î–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n\n"
        
        findings = analysis.get("main_findings", [])
        if findings:
            for i, finding in enumerate(findings, 1):
                conspect += f"{i}. {finding}\n"
        else:
            conclusions_list = [
                f"–¢–µ–º–∞ ¬´{topic}¬ª —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω–æ–π –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è",
                "–°—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ –∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é",
                "–†–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã —Ç—Ä–µ–±—É—é—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è",
                "–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏–º–µ—é—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
                "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"
            ]
            for i, conclusion in enumerate(conclusions_list, 1):
                conspect += f"{i}. {conclusion}\n"
        
        conspect += f"\n**–ü–ï–†–°–ü–ï–ö–¢–ò–í–ù–´–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ï–ì–û –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n\n"
        conspect += "1. –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Ç–µ–º—ã\n"
        conspect += "2. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤\n"
        conspect += "3. –ò–∑—É—á–µ–Ω–∏–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö\n"
        conspect += "4. –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Å–º–µ–∂–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π\n"
        conspect += "5. –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –º–µ—Ç–æ–¥–∏–∫ –∏–∑—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞–Ω–∏—è\n\n"
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        conspect += "=" * 60 + "\n"
        conspect += "–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø\n"
        conspect += "=" * 60 + "\n\n"
        
        conspect += f"*–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:* {datetime.now().strftime('%d.%m.%Y')}\n"
        conspect += f"*–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞:* {datetime.now().strftime('%H:%M')}\n"
        conspect += f"*–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:* –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n"
        conspect += f"*–û–±—ä–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:* –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä\n"
        conspect += f"*–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è:* –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ + —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n"
        conspect += f"*–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:* Google Search API + –£–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
        conspect += f"*–°–∏—Å—Ç–µ–º–∞:* @Konspekt_help_bot —Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º\n\n"
        
        conspect += "‚ö†Ô∏è **–í–ê–ñ–ù–û–ï –ü–†–ò–ú–ï–ß–ê–ù–ò–ï:** –î–∞–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–æ—Å–∏—Ç –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä "
        conspect += "–∏ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π. –î–ª—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è "
        conspect += "—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ."
        
        return conspect

# ==================== TELEGRAM BOT ====================
class TelegramBot:
    def __init__(self):
        if not TELEGRAM_TOKEN:
            raise ValueError("TELEGRAM_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        self.token = TELEGRAM_TOKEN
        self.bot_url = f"https://api.telegram.org/bot{self.token}"
        self.generator = SmartConspectGenerator()
        
        if RENDER_EXTERNAL_URL:
            self._setup_webhook()
        
        logger.info("‚úÖ –£–º–Ω—ã–π Telegram –±–æ—Ç –≥–æ—Ç–æ–≤")
    
    def _setup_webhook(self):
        webhook_url = f"{RENDER_EXTERNAL_URL}/webhook"
        try:
            response = requests.post(
                f"{self.bot_url}/setWebhook",
                json={"url": webhook_url},
                timeout=10
            )
            if response.json().get("ok"):
                logger.info(f"‚úÖ –í–µ–±—Ö—É–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {webhook_url}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ–±—Ö—É–∫–∞: {e}")
    
    def process_message(self, chat_id, text):
        text = text.strip()
        self._update_stats(chat_id)
        
        if text.startswith("/"):
            if text == "/start":
                return self._send_welcome(chat_id)
            elif text == "/help":
                return self._send_help(chat_id)
            elif text == "/stats":
                return self._send_stats(chat_id)
            elif text == "/example":
                return self._send_example(chat_id)
            else:
                return self._send_message(chat_id, "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help")
        
        if text in ["1", "2", "3"]:
            return self._handle_volume(chat_id, text)
        
        return self._handle_topic(chat_id, text)
    
    def _send_welcome(self, chat_id):
        welcome = (
            "üëã *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –£–º–Ω—ã–π Konspekt Helper Bot!*\n\n"
            "üß† *–Ø –Ω–µ –ø—Ä–æ—Å—Ç–æ –∏—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ‚Äî —è –µ—ë –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é!*\n\n"
            "üéØ *–ß—Ç–æ —è –¥–µ–ª–∞—é –ª—É—á—à–µ, —á–µ–º –æ–±—ã—á–Ω—ã–π Google:*\n"
            "‚Ä¢ üîç **–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é** –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n"
            "‚Ä¢ üèó **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é** –∑–Ω–∞–Ω–∏—è –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º\n"
            "‚Ä¢ üéØ **–í—ã–¥–µ–ª—è—é** –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–º—ã\n"
            "‚Ä¢ üìã **–°–æ—Å—Ç–∞–≤–ª—è—é** –ø–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è\n"
            "‚Ä¢ üí° **–î–∞—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** –ø–æ –∏–∑—É—á–µ–Ω–∏—é\n\n"
            "üìä *–¢—Ä–∏ —É—Ä–æ–≤–Ω—è –∞–Ω–∞–ª–∏–∑–∞:*\n"
            "‚Ä¢ *1* ‚Äî –ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–∫–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã)\n"
            "‚Ä¢ *2* ‚Äî –ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏)\n"
            "‚Ä¢ *3* ‚Äî –ü–æ–ª–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (–∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä)\n\n"
            "üöÄ *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±—É—é —Ç–µ–º—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.*"
        )
        return self._send_message(chat_id, welcome)
    
    def _send_help(self, chat_id):
        help_text = (
            "üìö *–ß–ï–ú –Ø –û–¢–õ–ò–ß–ê–Æ–°–¨ –û–¢ –û–ë–´–ß–ù–û–ì–û –ü–û–ò–°–ö–ê:*\n\n"
            "*Google –¥–∞–µ—Ç —Å—Å—ã–ª–∫–∏, —è –¥–∞—é –∑–Ω–∞–Ω–∏—è:*\n"
            "üîç **Google:** –ù–∞—Ö–æ–¥–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n"
            "üß† **–Ø:** –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n\n"
            "üîç **Google:** –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–Ω–∏–ø–ø–µ—Ç—ã\n"
            "üß† **–Ø:** –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n\n"
            "üîç **Google:** –ò—â–µ—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º\n"
            "üß† **–Ø:** –í—ã–¥–µ–ª—è—é –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã\n\n"
            "*–ü—Ä–∏–º–µ—Ä—ã —Ç–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:*\n"
            "‚Ä¢ –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω–µ\n"
            "‚Ä¢ –£—Å—Ç–æ–π—á–∏–≤–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –≥–æ—Ä–æ–¥–æ–≤\n"
            "‚Ä¢ –¶–∏—Ñ—Ä–æ–≤–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n"
            "‚Ä¢ –ë—É–¥—É—â–µ–µ –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏\n\n"
            "*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*\n"
            "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–º—É\n"
            "2. –í—ã–±–µ—Ä–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å –∞–Ω–∞–ª–∏–∑–∞ (1, 2 –∏–ª–∏ 3)\n"
            "3. –ü–æ–ª—É—á–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç\n\n"
            "üéØ *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /example*"
        )
        return self._send_message(chat_id, help_text)
    
    def _send_example(self, chat_id):
        example = (
            "üéØ *–ü–†–ò–ú–ï–† –ö–ê–ö –Ø –†–ê–ë–û–¢–ê–Æ:*\n\n"
            "*–ï—Å–ª–∏ –≤—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ:* ¬´–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç¬ª\n\n"
            "*Google –ø–æ–∫–∞–∂–µ—Ç:*\n"
            "‚Ä¢ –°—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏\n"
            "‚Ä¢ –û—Ç—Ä—ã–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞\n"
            "‚Ä¢ –°–ø–∏—Å–æ–∫ —Å–∞–π—Ç–æ–≤\n\n"
            "*–Ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—é:*\n\n"
            "üß† **–ê–ù–ê–õ–ò–ó:** –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Ç–µ–º–∞\n"
            "üîç **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** 7+ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n\n"
            "üéØ **–ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´:**\n"
            "1. –ò–ò —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –æ—Ç—Ä–∞—Å–ª–∏\n"
            "2. –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, NLP, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ\n"
            "3. –≠—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è\n\n"
            "üîë **–ö–õ–Æ–ß–ï–í–´–ï –¢–ï–†–ú–ò–ù–´:**\n"
            "‚Ä¢ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n"
            "‚Ä¢ –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n"
            "‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞\n"
            "‚Ä¢ –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ\n\n"
            "üèó **–°–¢–†–£–ö–¢–£–†–ê –ò–ó–£–ß–ï–ù–ò–Ø:**\n"
            "1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n"
            "2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã\n"
            "3. –û–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è\n"
            "4. –≠—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã\n"
            "5. –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è\n\n"
            "üí° **–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**\n"
            "–ò–∑—É—á–∞–π—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ò–ò –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ñ–µ—Ä–∞—Ö\n\n"
            "üöÄ *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∞–º–∏! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±—É—é —Ç–µ–º—É.*"
        )
        return self._send_message(chat_id, example)
    
    def _send_stats(self, chat_id):
        stat_text = (
            f"üìä *–°–¢–ê–¢–ò–°–¢–ò–ö–ê –£–ú–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê*\n\n"
            f"üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['total_users']}\n"
            f"üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: {stats['total_messages']}\n"
            f"üìÑ –ö–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {stats['conspects_created']}\n"
            f"üîç –ü–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['google_searches']}\n"
            f"‚è± –†–∞–±–æ—Ç–∞–µ—Ç —Å: {stats['start_time'][:10]}\n\n"
            f"üéØ –†–µ–∂–∏–º: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ"
        )
        return self._send_message(chat_id, stat_text)
    
    def _handle_topic(self, chat_id, topic):
        user_id = str(chat_id)
        if user_id not in stats["user_states"]:
            stats["user_states"][user_id] = {}
        
        stats["user_states"][user_id]["pending_topic"] = topic
        
        response = (
            f"üéØ *–¢–ï–ú–ê –ü–†–ò–ù–Ø–¢–ê: {topic}*\n\n"
            f"üß† *–ù–ê–ß–ò–ù–ê–Æ –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó...*\n\n"
            f"üîÑ *–Ø –°–î–ï–õ–ê–Æ:*\n"
            f"1. üîç –ü–æ–∏—Å–∫ –∏ —Å–±–æ—Ä –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n"
            f"2. üß† –ê–Ω–∞–ª–∏–∑ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n"
            f"3. üéØ –í—ã–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤\n"
            f"4. üìã –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n\n"
            f"üìä *–í–´–ë–ï–†–ò–¢–ï –£–†–û–í–ï–ù–¨ –ê–ù–ê–õ–ò–ó–ê:*\n\n"
            f"1Ô∏è‚É£ *–ö–†–ê–¢–ö–ò–ô –ê–ù–ê–õ–ò–ó*\n–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã –∏ —Ç–µ—Ä–º–∏–Ω—ã\n\n"
            f"2Ô∏è‚É£ *–ü–û–î–†–û–ë–ù–´–ô –ê–ù–ê–õ–ò–ó*\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞ + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ + –ø–ª–∞–Ω\n\n"
            f"3Ô∏è‚É£ *–ü–û–õ–ù–û–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï*\n–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä —Å –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–µ–π\n\n"
            f"üî¢ *–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ü–∏—Ñ—Ä—É 1, 2 –∏–ª–∏ 3*"
        )
        return self._send_message(chat_id, response)
    
    def _handle_volume(self, chat_id, volume_choice):
        user_id = str(chat_id)
        user_state = stats["user_states"].get(user_id, {})
        topic = user_state.get("pending_topic", "")
        
        if not topic:
            return self._send_message(chat_id, "‚ùå –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–º—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        volume_map = {"1": "short", "2": "detailed", "3": "extended"}
        volume = volume_map.get(volume_choice, "short")
        
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –∞–Ω–∞–ª–∏–∑–∞
        self._send_message(
            chat_id,
            f"üß† *–í–´–ü–û–õ–ù–Ø–Æ –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó...*\n\n"
            f"üìå –¢–µ–º–∞: {topic}\n"
            f"üìä –£—Ä–æ–≤–µ–Ω—å –∞–Ω–∞–ª–∏–∑–∞: {volume_choice}/3\n\n"
            f"‚è≥ –°–æ–±–∏—Ä–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é...\n"
            f"–≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥."
        )
        
        try:
            conspect = self.generator.generate(topic, volume)
            stats["conspects_created"] += 1
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–ø–µ–∫—Ç
            self._send_conspect_safely(chat_id, conspect)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            final_msg = (
                f"‚úÖ *–ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!*\n\n"
                f"üìå –¢–µ–º–∞: {topic}\n"
                f"üìä –£—Ä–æ–≤–µ–Ω—å –∞–Ω–∞–ª–∏–∑–∞: {volume_choice}/3\n"
                f"üîç –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {stats['google_searches']}\n"
                f"üìÑ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–µ–º: {stats['conspects_created']}\n\n"
                f"üéØ *–ß–¢–û –Ø –°–î–ï–õ–ê–õ:*\n"
                f"‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
                f"‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–ª –∑–Ω–∞–Ω–∏—è –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º\n"
                f"‚Ä¢ –í—ã–¥–µ–ª–∏–ª –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã –∏ —Ç–µ—Ä–º–∏–Ω—ã\n"
                f"‚Ä¢ –°–æ—Å—Ç–∞–≤–∏–ª —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–∑—É—á–µ–Ω–∏—é\n\n"
                f"üîÑ –î—Ä—É–≥–æ–π —É—Ä–æ–≤–µ–Ω—å –∞–Ω–∞–ª–∏–∑–∞? –û—Ç–ø—Ä–∞–≤—å—Ç–µ 1, 2 –∏–ª–∏ 3\n"
                f"üéØ –ù–æ–≤–∞—è —Ç–µ–º–∞? –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –µ—ë!"
            )
            return self._send_message(chat_id, final_msg)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return self._send_message(
                chat_id,
                f"‚ùå *–û–®–ò–ë–ö–ê –ê–ù–ê–õ–ò–ó–ê*\n\n"
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º—É. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                f"‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –ø–æ–∏—Å–∫–æ–≤—ã–º —Å–∏—Å—Ç–µ–º–∞–º\n"
                f"‚Ä¢ –°–ª–∏—à–∫–æ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∞—è –∏–ª–∏ –Ω–æ–≤–∞—è —Ç–µ–º–∞\n"
                f"‚Ä¢ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                f"1. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º—É\n"
                f"2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –æ–±—â–∏–µ –ø–æ–Ω—è—Ç–∏—è\n"
                f"3. –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É –ø–æ–∑–∂–µ\n\n"
                f"–û—à–∏–±–∫–∞: {str(e)[:100]}"
            )
    
    def _send_conspect_safely(self, chat_id, conspect):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        max_length = 4000
        
        if len(conspect) <= max_length:
            self._send_message(chat_id, conspect)
            return
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
        parts = re.split(r'(=+\n[^=]+\n=+|\n‚îÅ‚îÅ[‚îÅ]+\n)', conspect)
        
        current_part = ""
        result_parts = []
        
        for part in parts:
            if not part.strip():
                continue
            
            if re.match(r'(=+\n[^=]+\n=+|\n‚îÅ‚îÅ[‚îÅ]+\n)', part):
                if current_part and len(current_part) > 1000:
                    result_parts.append(current_part.strip())
                    current_part = part + "\n\n"
                else:
                    current_part += part + "\n\n"
            else:
                if len(current_part + part) > max_length and current_part:
                    result_parts.append(current_part.strip())
                    current_part = part
                else:
                    current_part += part
        
        if current_part.strip():
            result_parts.append(current_part.strip())
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        if not result_parts or (len(result_parts) == 1 and len(result_parts[0]) > max_length):
            paragraphs = conspect.split('\n\n')
            result_parts = []
            current = ""
            
            for para in paragraphs:
                if len(current + para) > max_length and current:
                    result_parts.append(current.strip())
                    current = para
                else:
                    if current:
                        current += "\n\n" + para
                    else:
                        current = para
            
            if current.strip():
                result_parts.append(current.strip())
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
        total_parts = len(result_parts)
        for i, part in enumerate(result_parts, 1):
            if i > 1:
                header = f"üìñ *–ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –ê–ù–ê–õ–ò–ó–ê ({i}/{total_parts})*\n\n"
                part = header + part
            
            if len(part) > max_length:
                # –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
                sub_parts = [part[j:j+max_length] for j in range(0, len(part), max_length)]
                for sub_part in sub_parts:
                    self._send_message(chat_id, sub_part)
                    import time
                    time.sleep(0.3)
            else:
                self._send_message(chat_id, part)
                if i < total_parts:
                    import time
                    time.sleep(0.5)
    
    def _update_stats(self, chat_id):
        user_id = str(chat_id)
        
        if user_id not in stats["user_states"]:
            stats["total_users"] += 1
            stats["user_states"][user_id] = {
                "first_seen": datetime.now().isoformat(),
                "message_count": 0
            }
        
        stats["user_states"][user_id]["last_seen"] = datetime.now().isoformat()
        stats["user_states"][user_id]["message_count"] += 1
        stats["total_messages"] += 1
    
    def _send_message(self, chat_id, text):
        try:
            response = requests.post(
                f"{self.bot_url}/sendMessage",
                json={
                    "chat_id": chat_id,
                    "text": text,
                    "parse_mode": "Markdown",
                    "disable_web_page_preview": True
                },
                timeout=15
            )
            return response.json().get("ok", False)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
            return False

# [–û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ HTTP —Å–µ—Ä–≤–µ—Ä–∞ –∏ –∑–∞–ø—É—Å–∫–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
# –ü—Ä–æ—Å—Ç–æ –≤—Å—Ç–∞–≤—å —Å—é–¥–∞ –∫–æ–¥ HTTP —Å–µ—Ä–≤–µ—Ä–∞ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
# –∏ –∑–∞–ø—É—Å–∫–∞ main()

# ==================== HTTP –°–ï–†–í–ï–† ====================
class BotHTTPServer(BaseHTTPRequestHandler):
    def do_GET(self):
        path = self.path.split('?')[0]
        
        if path == "/":
            self._send_html(INDEX_HTML)
        elif path == "/health":
            self._send_json({"status": "ok", "time": datetime.now().isoformat()})
        elif path == "/stats":
            self._send_json(stats)
        else:
            self.send_response(404)
            self.end_headers()
    
    def do_POST(self):
        if self.path == "/webhook":
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length:
                try:
                    data = self.rfile.read(content_length)
                    update = json.loads(data.decode('utf-8'))
                    
                    threading.Thread(
                        target=self._handle_update,
                        args=(update,),
                        daemon=True
                    ).start()
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ–±—Ö—É–∫–∞: {e}")
            
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b'OK')
        else:
            self.send_response(404)
            self.end_headers()
    
    def _handle_update(self, update):
        try:
            if "message" in update and "text" in update["message"]:
                chat_id = update["message"]["chat"]["id"]
                text = update["message"]["text"]
                
                bot = TelegramBot()
                bot.process_message(chat_id, text)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    
    def _send_html(self, content):
        self.send_response(200)
        self.send_header('Content-Type', 'text/html; charset=utf-8')
        self.end_headers()
        self.wfile.write(content.encode('utf-8'))
    
    def _send_json(self, data):
        self.send_response(200)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.end_headers()
        self.wfile.write(json.dumps(data, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def log_message(self, format, *args):
        pass

INDEX_HTML = """<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ü§ñ –£–º–Ω—ã–π Konspekt Helper Bot</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
        .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .status { color: green; font-weight: bold; padding: 10px; background: #e8f5e8; border-radius: 5px; }
        .comparison { background: #f0f9ff; padding: 20px; border-radius: 5px; margin: 20px 0; border-left: 4px solid #3b82f6; }
        .btn { display: inline-block; background: #0088cc; color: white; padding: 10px 20px; border-radius: 5px; text-decoration: none; margin: 5px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ü§ñ –£–º–Ω—ã–π Konspekt Helper Bot</h1>
        <p class="status">‚úÖ –†–µ–∂–∏–º: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏</p>
        <p>Telegram –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –ø—Ä–æ—Å—Ç–æ –∏—â–µ—Ç, –∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞–Ω–∏—è</p>
        
        <div class="comparison">
            <h3>üß† –ß–µ–º —è –ª—É—á—à–µ –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:</h3>
            <p><strong>Google:</strong> –ù–∞—Ö–æ–¥–∏—Ç —Å—Å—ã–ª–∫–∏ –∏ —Å–Ω–∏–ø–ø–µ—Ç—ã</p>
            <p><strong>–Ø:</strong> –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É—é, –≤—ã–¥–µ–ª—è—é –∫–ª—é—á–µ–≤–æ–µ, –¥–∞—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</p>
        </div>
        
        <h3>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã:</h3>
        <div id="stats">–ó–∞–≥—Ä—É–∑–∫–∞...</div>
        
        <h3>üîó –ë—ã—Å—Ç—Ä—ã–µ —Å—Å—ã–ª–∫–∏:</h3>
        <div>
            <a href="https://t.me/Konspekt_help_bot" class="btn" target="_blank">ü§ñ –û—Ç–∫—Ä—ã—Ç—å –±–æ—Ç–∞</a>
            <a href="/stats" class="btn">üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</a>
            <a href="/health" class="btn">‚ù§Ô∏è Health Check</a>
        </div>
        
        <h3>üéØ –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã:</h3>
        <p>–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–º—É "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç" –∏ –ø–æ–ª—É—á–∏—Ç–µ:</p>
        <ul>
            <li>üß† <strong>–ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ —Ç–µ–º—ã</strong> (—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è)</li>
            <li>üéØ <strong>–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã</strong> –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤</li>
            <li>üîë <strong>–ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã</strong> –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è</li>
            <li>üèó <strong>–°—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑—É—á–µ–Ω–∏—è</strong> –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º</li>
            <li>üí° <strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</strong> –ø–æ –∏–∑—É—á–µ–Ω–∏—é</li>
            <li>üìã <strong>–ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π</strong> –¥–ª—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è</li>
        </ul>
        
        <p style="color: #666; margin-top: 30px;">
            –°–∏—Å—Ç–µ–º–∞ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –û–±–Ω–æ–≤–ª–µ–Ω–æ: <span id="time"></span>
        </p>
    </div>
    
    <script>
        async function loadStats() {
            try {
                const response = await fetch('/stats');
                const data = await response.json();
                
                document.getElementById('stats').innerHTML = `
                    <p>üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: ${data.total_users || 0}</p>
                    <p>üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: ${data.total_messages || 0}</p>
                    <p>üìÑ –ö–æ–Ω—Å–ø–µ–∫—Ç–æ–≤: ${data.conspects_created || 0}</p>
                    <p>üîç –ü–æ–∏—Å–∫–æ–≤: ${data.google_searches || 0}</p>
                `;
                
                document.getElementById('time').textContent = new Date().toLocaleTimeString();
            } catch (error) {
                document.getElementById('stats').innerHTML = '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏';
            }
        }
        
        loadStats();
        setInterval(loadStats, 5000);
    </script>
</body>
</html>
"""

# ==================== –ó–ê–ü–£–°–ö ====================
def main():
    logger.info("=" * 60)
    logger.info("üöÄ –ó–ê–ü–£–°–ö –£–ú–ù–û–ì–û KONSPEKT BOT")
    logger.info("=" * 60)
    logger.info(f"üåê URL: {RENDER_EXTERNAL_URL}")
    logger.info(f"üö™ –ü–æ—Ä—Ç: {PORT}")
    logger.info("‚úÖ –†–µ–∂–∏–º: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ")
    logger.info("‚úÖ –í—Å–µ —Ç—Ä–∏ —É—Ä–æ–≤–Ω—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–±–æ—Ç–∞—é—Ç")
    logger.info("=" * 60)
    
    server = HTTPServer(('', PORT), BotHTTPServer)
    logger.info(f"‚úÖ HTTP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()
