#!/usr/bin/env python3
"""
Konspekt Helper Bot - –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import os
import logging
import json
import requests
from datetime import datetime
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading
import random
import re

# ==================== –ù–ê–°–¢–†–û–ô–ö–ê ====================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID", "13aac457275834df9")
RENDER_EXTERNAL_URL = os.getenv("RENDER_EXTERNAL_URL", "")
PORT = int(os.getenv("PORT", 10000))

if not TELEGRAM_TOKEN:
    logger.error("‚ùå TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    exit(1)

# ==================== –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================
stats = {
    "total_users": 0,
    "total_messages": 0,
    "conspects_created": 0,
    "google_searches": 0,
    "start_time": datetime.now().isoformat(),
    "user_states": {}
}

# ==================== –£–õ–£–ß–®–ï–ù–ù–´–ô GOOGLE SEARCH API ====================
class EnhancedGoogleSearchAPI:
    def __init__(self):
        self.api_key = GOOGLE_API_KEY
        self.cse_id = GOOGLE_CSE_ID
        self.base_url = "https://www.googleapis.com/customsearch/v1"
        self.cache = {}
        
    def search(self, query, num_results=7):
        """–ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not query or len(query.strip()) < 2:
            return self._create_empty_result(query)
        
        cache_key = f"{query}_{num_results}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        stats["google_searches"] += 1
        
        params = {
            "key": self.api_key,
            "cx": self.cse_id,
            "q": query,
            "num": min(num_results, 10),
            "hl": "ru",
            "lr": "lang_ru",
            "gl": "ru",
            "cr": "countryRU"
        }
        
        try:
            logger.info(f"üîç –ü–æ–∏—Å–∫: {query}")
            response = requests.get(self.base_url, params=params, timeout=15)
            
            if response.status_code != 200:
                logger.warning(f"–û—à–∏–±–∫–∞ API: {response.status_code}")
                return self._create_intelligent_fallback(query)
            
            data = response.json()
            result = self._process_and_filter_results(data, query)
            self.cache[cache_key] = result
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return self._create_intelligent_fallback(query)
    
    def _process_and_filter_results(self, data, query):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞"""
        raw_items = data.get("items", [])
        filtered_items = []
        all_text = ""
        query_words = set(query.lower().split())
        
        for item in raw_items:
            title = item.get("title", "")
            snippet = item.get("snippet", "")
            link = item.get("link", "")
            source = item.get("displayLink", "")
            
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
            title = self._clean_text(title)
            snippet = self._clean_text(snippet)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if not snippet or len(snippet) < 20:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if not self._is_quality_content(title, snippet, query_words):
                continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–Ω–∏–ø–ø–µ—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –º—É—Å–æ—Ä–∞
            processed_snippet = self._process_snippet(snippet, query)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
            if len(processed_snippet) < 30:
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–µ–º—É —Ç–µ–∫—Å—Ç—É
            all_text += f"{processed_snippet} "
            
            filtered_items.append({
                "title": title,
                "snippet": processed_snippet,
                "link": link,
                "source": source,
                "full_text": f"{title}. {processed_snippet}",
                "relevance_score": self._calculate_relevance(title, processed_snippet, query_words)
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        filtered_items.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        best_items = filtered_items[:5]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        keywords = self._extract_keywords_from_filtered(all_text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º—É
        topic_info = self._analyze_topic(query, best_items)
        
        return {
            "success": True,
            "query": query,
            "items": best_items,
            "total_raw": len(raw_items),
            "total_filtered": len(best_items),
            "keywords": keywords,
            "topic_info": topic_info,
            "all_text": all_text[:3000],
            "timestamp": datetime.now().isoformat()
        }
    
    def _is_quality_content(self, title, snippet, query_words):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        text = f"{title} {snippet}".lower()
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        low_quality_indicators = [
            "?",  # –í–æ–ø—Ä–æ—Å—ã
            "—Ñ–æ—Ä—É–º", "–æ–±—Å—É–∂–¥–µ–Ω", "–∫–æ–º–º–µ–Ω—Ç–∞—Ä",  # –û–±—Å—É–∂–¥–µ–Ω–∏—è
            "–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å", "–∫–∞–∫ —É–∑–Ω–∞—Ç—å", "–∫–∞–∫ –ø–æ–Ω—è—Ç—å",  # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            "—á—Ç–æ —Ç–∞–∫–æ–µ", "–∫—Ç–æ —Ç–∞–∫–æ–π",  # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–∏–Ω–æ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–æ, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞)
            "–≤–∏–¥–µ–æ", "—Å–º–æ—Ç—Ä–µ—Ç—å –æ–Ω–ª–∞–π–Ω",  # –ú–µ–¥–∏–∞
            "–∫—É–ø–∏—Ç—å", "–ø—Ä–æ–¥–∞—Ç—å", "—Ü–µ–Ω–∞", "–∑–∞–∫–∞–∑–∞—Ç—å",  # –ö–æ–º–º–µ—Ä—Ü–∏—è
            "–æ—Ç–∑—ã–≤", "—Ä–µ—Ü–µ–Ω–∑",  # –û—Ç–∑—ã–≤—ã
            "—á–∞—Ç", "—Å–æ–æ–±—â–µ—Å—Ç–≤",  # –°–æ–æ–±—â–µ—Å—Ç–≤–∞
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        for indicator in low_quality_indicators:
            if indicator in text:
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å—É
        relevance_words = 0
        for word in query_words:
            if len(word) > 3 and word in text:
                relevance_words += 1
        
        # –ï—Å–ª–∏ –º–µ–Ω–µ–µ 30% —Å–ª–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç, —Å—á–∏—Ç–∞–µ–º –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º
        if query_words and relevance_words / len(query_words) < 0.3:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if len(snippet) < 50 or len(snippet) > 500:
            return False
            
        return True
    
    def _process_snippet(self, snippet, query):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–Ω–∏–ø–ø–µ—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –º—É—Å–æ—Ä–∞"""
        # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
        snippet = re.sub(r'<[^>]+>', '', snippet)
        
        # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏
        snippet = re.sub(r'https?://\S+', '', snippet)
        
        # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é)
        snippet = re.sub(r'[^\w\s–∞-—è–ê-–Ø—ë–Å.,!?-]', ' ', snippet)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        snippet = re.sub(r'\s+', ' ', snippet).strip()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', snippet)
        filtered_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–æ–ø—Ä–æ—Å—ã
            if sentence.endswith('?'):
                continue
                
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if len(sentence) < 20:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            if self._is_informative_sentence(sentence):
                filtered_sentences.append(sentence)
        
        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        processed = '. '.join(filtered_sentences[:3])  # –ë–µ—Ä–µ–º –¥–æ 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        if processed and not processed.endswith('.'):
            processed += '.'
        
        return processed if processed else snippet
    
    def _is_informative_sentence(self, sentence):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º"""
        sentence_lower = sentence.lower()
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        non_informative = [
            "–∫–∞–∫ ", "–ø–æ—á–µ–º—É ", "–∑–∞—á–µ–º ", "–∫–æ–≥–¥–∞ ",
            "–≤–æ–∑–º–æ–∂–Ω–æ ", "–≤–µ—Ä–æ—è—Ç–Ω–æ ", "–Ω–∞–≤–µ—Ä–Ω–æ–µ ",
            "—Å–ø—Ä–æ—Å–∏–ª ", "–æ—Ç–≤–µ—Ç–∏–ª ", "—Å–∫–∞–∑–∞–ª ",
            "—á–∏—Ç–∞–π—Ç–µ —Ç–∞–∫–∂–µ", "–ø–æ–¥—Ä–æ–±–Ω–µ–µ", "—Å–º–æ—Ç—Ä–∏—Ç–µ",
            "—Ñ–æ—Ç–æ:", "–≤–∏–¥–µ–æ:"
        ]
        
        for indicator in non_informative:
            if sentence_lower.startswith(indicator):
                return False
        
        # –î–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≥–ª–∞–≥–æ–ª—ã –∏ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ
        words = sentence_lower.split()
        verb_like = any(word.endswith(('—Ç—å', '–ª—Å—è', '–ª–∞—Å—å', '–ª–æ—Å—å', '–ª–∏—Å—å')) for word in words)
        
        return len(words) >= 4 and verb_like
    
    def _calculate_relevance(self, title, snippet, query_words):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        text = f"{title} {snippet}".lower()
        score = 0
        
        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        for word in query_words:
            if len(word) > 3:
                if word in text:
                    score += 2
                if word in title.lower():
                    score += 3
        
        # –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è 100-300 —Å–∏–º–≤–æ–ª–æ–≤)
        if 100 <= len(snippet) <= 300:
            score += 2
        
        # –ù–∞–ª–∏—á–∏–µ —Ü–∏—Ñ—Ä –∏ —Ñ–∞–∫—Ç–æ–≤
        if re.search(r'\d+', snippet):
            score += 1
        
        # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤
        if '?' not in snippet:
            score += 1
        
        return score
    
    def _extract_keywords_from_filtered(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        stop_words = {
            "–∏", "–≤", "–Ω–∞", "—Å", "–ø–æ", "–æ", "–æ–±", "–¥–ª—è", "–∏–∑", "–æ—Ç",
            "—ç—Ç–æ", "—á—Ç–æ", "–∫–∞–∫", "–Ω–æ", "–∞", "–∏–ª–∏", "–µ—Å–ª–∏", "—Ç–æ", "–∂–µ",
            "–±—ã", "–ª–∏", "–Ω–µ—Ç", "–¥–∞", "–æ–Ω", "–æ–Ω–∞", "–æ–Ω–æ", "–æ–Ω–∏", "–º—ã",
            "–≤—ã", "—Ç—ã", "—è", "–º–µ–Ω—è", "—Ç–µ–±—è", "–µ–≥–æ", "–µ–µ", "–Ω–∞–º", "–≤–∞–º"
        }
        
        # –ù–∞—Ö–æ–¥–∏–º —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞ –æ—Ç 3 –±—É–∫–≤
        words = re.findall(r'\b[–∞-—è—ë]{3,}\b', text.lower())
        
        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
        word_freq = {}
        for word in words:
            if word not in stop_words:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_words[:10]]
    
    def _analyze_topic(self, query, items):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–º—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not items:
            return {"category": "–æ–±—â–∞—è —Ç–µ–º–∞", "complexity": "–±–∞–∑–æ–≤–∞—è"}
        
        categories = {
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": ["—Ç–µ—Ö–Ω–æ–ª–æ–≥", "–∏–∏", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω", "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä", "–∫–æ–º–ø—å—é—Ç–µ—Ä", "—Ä–æ–±–æ—Ç", "—Å–æ—Ñ—Ç", "–∞–ø–ø–∞—Ä–∞—Ç"],
            "—ç–∫–æ–Ω–æ–º–∏–∫–∞": ["—ç–∫–æ–Ω–æ–º–∏–∫", "—Ñ–∏–Ω–∞–Ω—Å", "—Ä—ã–Ω–æ–∫", "–±–∏–∑–Ω–µ—Å", "–∏–Ω—Ñ–ª—è—Ü", "–≤–∞–ª—é—Ç–∞", "–±–∞–Ω–∫", "–∏–Ω–≤–µ—Å—Ç–∏—Ü"],
            "–Ω–∞—É–∫–∞": ["–Ω–∞—É–∫", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω", "—É—á–µ–Ω", "—Ñ–∏–∑–∏–∫", "—Ö–∏–º–∏", "–±–∏–æ–ª–æ–≥", "–∫–æ—Å–º–æ—Å", "–æ—Ç–∫—Ä—ã—Ç"],
            "–º–µ–¥–∏—Ü–∏–Ω–∞": ["–º–µ–¥–∏—Ü–∏–Ω", "–∑–¥–æ—Ä–æ–≤", "–±–æ–ª–µ–∑–Ω", "–ª–µ—á–µ–Ω", "–≤—Ä–∞—á", "–±–æ–ª—å–Ω–∏—Ü", "–≤–∏—Ä—É—Å"],
            "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω", "–æ–±—É—á–µ–Ω", "—à–∫–æ–ª", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç", "—Å—Ç—É–¥–µ–Ω—Ç", "–ø—Ä–µ–ø–æ–¥–∞–≤–∞–Ω"],
            "–∏—Å—Ç–æ—Ä–∏—è": ["–∏—Å—Ç–æ—Ä–∏", "–≤–æ–π–Ω", "—Å—Ä–∞–∂–µ–Ω", "–¥—Ä–µ–≤–Ω", "—Å—Ä–µ–¥–Ω–µ–≤–µ–∫–æ–≤", "—Ä–µ–≤–æ–ª—é—Ü"],
            "–∫—É–ª—å—Ç—É—Ä–∞": ["–∫—É–ª—å—Ç—É—Ä", "–∏—Å–∫—É—Å—Å—Ç–≤", "–º—É–∑—ã–∫", "–∫–∏–Ω–æ", "—Ç–µ–∞—Ç—Ä", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä"]
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã
        all_text = " ".join([item.get("full_text", "") for item in items]).lower()
        
        detected_category = "–æ–±—â–∞—è —Ç–µ–º–∞"
        max_score = 0
        
        for category, keywords in categories.items():
            score = 0
            for keyword in keywords:
                if keyword in query.lower():
                    score += 2
                if keyword in all_text:
                    score += 1
            
            if score > max_score:
                max_score = score
                detected_category = category
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        complexity = "–±–∞–∑–æ–≤–∞—è"
        total_text_length = sum(len(item.get("full_text", "")) for item in items)
        if total_text_length > 2000:
            complexity = "—Å–ª–æ–∂–Ω–∞—è"
        elif total_text_length > 1000:
            complexity = "—Å—Ä–µ–¥–Ω—è—è"
        
        return {
            "category": detected_category,
            "complexity": complexity,
            "has_quality_data": len(items) > 0,
            "avg_relevance": sum(item.get("relevance_score", 0) for item in items) / max(len(items), 1)
        }
    
    def _clean_text(self, text):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç"""
        if not text:
            return ""
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def _create_intelligent_fallback(self, query):
        """–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π fallback –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º—ã"""
        logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π fallback –¥–ª—è: {query}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–∞
        category_keywords = {
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": ["—Ç–µ—Ö–Ω–æ–ª–æ–≥", "–∏–∏", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω", "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä", "–∫–æ–º–ø—å—é—Ç–µ—Ä", "—Ä–æ–±–æ—Ç"],
            "—ç–∫–æ–Ω–æ–º–∏–∫–∞": ["—ç–∫–æ–Ω–æ–º–∏–∫", "—Ñ–∏–Ω–∞–Ω—Å", "—Ä—ã–Ω–æ–∫", "–±–∏–∑–Ω–µ—Å", "–∏–Ω—Ñ–ª—è—Ü", "–≤–∞–ª—é—Ç–∞"],
            "–Ω–∞—É–∫–∞": ["–Ω–∞—É–∫", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω", "—É—á–µ–Ω", "—Ñ–∏–∑–∏–∫", "—Ö–∏–º–∏", "–±–∏–æ–ª–æ–≥"],
            "–º–µ–¥–∏—Ü–∏–Ω–∞": ["–º–µ–¥–∏—Ü–∏–Ω", "–∑–¥–æ—Ä–æ–≤", "–±–æ–ª–µ–∑–Ω", "–ª–µ—á–µ–Ω", "–≤—Ä–∞—á"],
            "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω", "–æ–±—É—á–µ–Ω", "—à–∫–æ–ª", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç"]
        }
        
        detected_category = "–æ–±—â–∞—è —Ç–µ–º–∞"
        query_lower = query.lower()
        
        for category, keywords in category_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                detected_category = category
                break
        
        # –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è fallback
        fallback_data = {
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": {
                "title": "–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏",
                "content": "–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Ä–∞–∑–≤–∏–≤–∞—é—Ç—Å—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ, –∑–∞—Ç—Ä–∞–≥–∏–≤–∞—è –≤—Å–µ —Å—Ñ–µ—Ä—ã –∂–∏–∑–Ω–∏. –ö–ª—é—á–µ–≤—ã–º–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ —è–≤–ª—è—é—Ç—Å—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –≤–µ—â–µ–π –∏ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è. –≠—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É—é—Ç –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã, –º–µ–¥–∏—Ü–∏–Ω—É, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—É—é –∂–∏–∑–Ω—å.",
                "aspects": ["–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ", "–û–±–ª–∞—á–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"]
            },
            "—ç–∫–æ–Ω–æ–º–∏–∫–∞": {
                "title": "–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã",
                "content": "–≠–∫–æ–Ω–æ–º–∏–∫–∞ –∏–∑—É—á–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏ —É—Å–ª—É–≥. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—Ç—Å—è –≥–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏–µ–π, —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–µ–π –∏ —É—Å—Ç–æ–π—á–∏–≤—ã–º —Ä–∞–∑–≤–∏—Ç–∏–µ–º. –í–∞–∂–Ω—ã–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏ —è–≤–ª—è—é—Ç—Å—è –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, —Ñ–∏—Å–∫–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è.",
                "aspects": ["–ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞", "–ú–∏–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞", "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è", "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä—ã–Ω–∫–∏", "–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç"]
            },
            "–Ω–∞—É–∫–∞": {
                "title": "–ù–∞—É—á–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –æ—Ç–∫—Ä—ã—Ç–∏—è",
                "content": "–ù–∞—É–∫–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –ø–æ–ª—É—á–µ–Ω–∏—é –Ω–æ–≤—ã—Ö –∑–Ω–∞–Ω–∏–π –æ –ø—Ä–∏—Ä–æ–¥–µ, –æ–±—â–µ—Å—Ç–≤–µ –∏ –º—ã—à–ª–µ–Ω–∏–∏. –ù–∞—É—á–Ω—ã–π –º–µ—Ç–æ–¥ –æ—Å–Ω–æ–≤—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ. –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–∞—É–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç—Å—è –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω–æ—Å—Ç—å—é –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º.",
                "aspects": ["–§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–ü—Ä–∏–∫–ª–∞–¥–Ω–∞—è –Ω–∞—É–∫–∞", "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã", "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏", "–ù–∞—É—á–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è"]
            },
            "–æ–±—â–∞—è —Ç–µ–º–∞": {
                "title": f"–ê–Ω–∞–ª–∏–∑ —Ç–µ–º—ã: {query}",
                "content": f"–¢–µ–º–∞ '{query}' –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É, —Ç—Ä–µ–±—É—é—â—É—é –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è. –î–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Ä–∞–∑–≤–∏—Ç–∏—è. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ.",
                "aspects": ["–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã", "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ", "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç", "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ", "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è"]
            }
        }
        
        data = fallback_data[detected_category]
        
        items = [{
            "title": data["title"],
            "snippet": data["content"],
            "full_text": data["content"],
            "source": "–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞",
            "relevance_score": 5,
            "aspects": data["aspects"]
        }]
        
        return {
            "success": False,
            "query": query,
            "items": items,
            "total_filtered": 1,
            "keywords": query.lower().split()[:5],
            "topic_info": {
                "category": detected_category,
                "complexity": "–±–∞–∑–æ–≤–∞—è",
                "has_quality_data": True,
                "fallback": True
            },
            "all_text": data["content"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _create_empty_result(self, query):
        """–°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        return {
            "success": False,
            "query": query,
            "items": [],
            "total_filtered": 0,
            "keywords": [],
            "topic_info": {
                "category": "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                "complexity": "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞",
                "has_quality_data": False
            },
            "all_text": "",
            "timestamp": datetime.now().isoformat()
        }

# ==================== –ì–ï–ù–ï–†–ê–¢–û–† –ö–û–ù–°–ü–ï–ö–¢–û–í ====================
class ConspectGenerator:
    def __init__(self):
        self.searcher = EnhancedGoogleSearchAPI()
        logger.info("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –≥–æ—Ç–æ–≤")
    
    def generate(self, topic, volume="short"):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–ø–µ–∫—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ü–∞—Å—Ö–∞–ª–∫–∞
        if self._is_easter_egg(topic):
            return self._create_easter_egg_response()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        search_results = self.searcher.search(topic)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞
        if volume == "detailed":
            return self._generate_detailed(topic, search_results)
        elif volume == "extended":
            return self._generate_extended(topic, search_results)
        else:
            return self._generate_short(topic, search_results)
    
    def _is_easter_egg(self, text):
        text_lower = text.lower()
        return any(phrase in text_lower for phrase in [
            "–ø–ª–∞–Ω –∑–∞—Ö–≤–∞—Ç–∞ –ø–æ–ª—å—à–∏", "–∑–∞—Ö–≤–∞—Ç –ø–æ–ª—å—à–∏", "—á–∞–π–Ω–∞—è –ø–∞—Å—Ö–∞–ª–∫–∞"
        ])
    
    def _create_easter_egg_response(self):
        responses = [
            "üçµ *–°–µ–∫—Ä–µ—Ç–Ω–∞—è –ø–∞—Å—Ö–∞–ª–∫–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞!*\n\n–°—Ç–∞—Ç—É—Å: –ß–∞–π–Ω—ã–π –ú–∞—Å—Ç–µ—Ä\n–§–æ–∫—Å—è –≤ –ø—É—Ç–∏...",
            "üçµ *Easter Egg Found!*\n\nTea Status: ACTIVE\nFoksya incoming..."
        ]
        return random.choice(responses)
    
    def _generate_short(self, topic, results):
        """–ö—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Å–ø–µ–∫—Ç"""
        items = results.get("items", [])
        topic_info = results.get("topic_info", {})
        
        conspect = f"üìÑ *–ö–û–ù–°–ü–ï–ö–¢: {topic.upper()}*\n\n"
        conspect += f"üîç *–ö–∞—Ç–µ–≥–æ—Ä–∏—è:* {topic_info.get('category', '–æ–±—â–∞—è —Ç–µ–º–∞')}\n"
        conspect += f"üìä *–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:* {results.get('total_filtered', 0)}\n\n"
        
        conspect += "üìù *–û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:*\n\n"
        
        if items:
            for i, item in enumerate(items[:2], 1):
                text = item.get("snippet", "")
                if text:
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    if len(text) > 200:
                        text = text[:200] + "..."
                    conspect += f"{i}. {text}\n\n"
        else:
            conspect += "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞.\n\n"
        
        conspect += "üéØ *–ö–õ–Æ–ß–ï–í–´–ï –ê–°–ü–ï–ö–¢–´:*\n"
        keywords = results.get("keywords", [])
        if keywords:
            for i, keyword in enumerate(keywords[:4], 1):
                conspect += f"{i}. {keyword.capitalize()}\n"
        else:
            for i in range(1, 5):
                conspect += f"{i}. –í–∞–∂–Ω—ã–π –∞—Å–ø–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n"
        
        conspect += f"\nüí° *–í–´–í–û–î:* –¢–µ–º–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–µ—Å –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–∑—É—á–µ–Ω–∏—è.\n\n"
        conspect += "ü§ñ *@Konspekt_help_bot* | üîç *–§–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ Google*"
        
        return conspect
    
    def _generate_detailed(self, topic, results):
        """–ü–æ–¥—Ä–æ–±–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô - –Ω–µ –ø—É—Å—Ç–æ–π)"""
        items = results.get("items", [])
        topic_info = results.get("topic_info", {})
        
        conspect = f"üìö *–ü–û–î–†–û–ë–ù–´–ô –ê–ù–ê–õ–ò–ó: {topic.upper()}*\n\n"
        
        # –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üî¨ *–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        conspect += f"*–ó–∞–ø—Ä–æ—Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:* {topic}\n"
        conspect += f"*–ö–∞—Ç–µ–≥–æ—Ä–∏—è:* {topic_info.get('category', '–æ–±—â–∞—è —Ç–µ–º–∞')}\n"
        conspect += f"*–°–ª–æ–∂–Ω–æ—Å—Ç—å:* {topic_info.get('complexity', '–±–∞–∑–æ–≤–∞—è')}\n"
        conspect += f"*–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:* {results.get('total_filtered', 0)} –∏–∑ {results.get('total_raw', 0)}\n"
        conspect += f"*–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞:* {datetime.now().strftime('%H:%M')}\n\n"
        
        # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üìä *–ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        if items:
            for i, item in enumerate(items, 1):
                title = item.get("title", f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i}")
                text = item.get("snippet", "")
                source = item.get("source", "–∏—Å—Ç–æ—á–Ω–∏–∫")
                
                conspect += f"**{i}. {title}**\n"
                conspect += f"{text}\n"
                conspect += f"*–ò—Å—Ç–æ—á–Ω–∏–∫:* {source}\n"
                conspect += f"*–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:* {'–≤—ã—Å–æ–∫–∞—è' if item.get('relevance_score', 0) > 3 else '—Å—Ä–µ–¥–Ω—è—è'}\n\n"
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
            conspect += "**–ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –û–ë–ó–û–†:**\n"
            conspect += f"–ü–æ —Ç–µ–º–µ '{topic}' –±—ã–ª –ø—Ä–æ–≤–µ–¥–µ–Ω –∞–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. "
            conspect += "–û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–Ω–∞–Ω–∏–π –∏ –¥–∞–Ω–Ω—ã—Ö.\n\n"
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üèó *–°–¢–†–£–ö–¢–£–†–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–ï–ú–´*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–ø–µ–∫—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
        aspects_to_use = []
        
        if items and items[0].get("aspects"):
            aspects_to_use = items[0]["aspects"][:5]
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
            category = topic_info.get("category", "–æ–±—â–∞—è —Ç–µ–º–∞")
            aspect_templates = {
                "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": [
                    "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã",
                    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —Ä–µ—à–µ–Ω–∏—è", 
                    "–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Ä–∞–∑–≤–∏—Ç–∏—è –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏",
                    "–≠—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã",
                    "–ë—É–¥—É—â–∏–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã"
                ],
                "—ç–∫–æ–Ω–æ–º–∏–∫–∞": [
                    "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏",
                    "–†—ã–Ω–æ—á–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã",
                    "–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ",
                    "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
                    "–ü—Ä–æ–≥–Ω–æ–∑—ã –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–∞–∑–≤–∏—Ç–∏—è"
                ],
                "–Ω–∞—É–∫–∞": [
                    "–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã",
                    "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                    "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã",
                    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
                    "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π"
                ]
            }
            
            aspects_to_use = aspect_templates.get(category, [
                "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã",
                "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç",
                "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ",
                "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è"
            ])
        
        conspect += "*–ö–õ–Æ–ß–ï–í–´–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø –ê–ù–ê–õ–ò–ó–ê:*\n\n"
        for i, aspect in enumerate(aspects_to_use, 1):
            conspect += f"{i}. **{aspect}**\n"
            conspect += f"   –î–∞–Ω–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –≤ —Ä–∞–º–∫–∞—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ç–µ–º—ã.\n\n"
        
        # –í—ã–≤–æ–¥—ã
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        conspect += "üíé *–í–´–í–û–î–´ –ò –ó–ê–ö–õ–Æ–ß–ï–ù–ò–Ø*\n"
        conspect += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        conspect += "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –≤—ã–≤–æ–¥—ã:\n\n"
        
        conclusions = [
            "–¢–µ–º–∞ –æ–±–ª–∞–¥–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
            "–°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –∏–∑—É—á–µ–Ω–∏—é –≤–æ–ø—Ä–æ—Å–∞",
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–∞–∑–∞ —Ç—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è",
            "–ò–º–µ—é—Ç—Å—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
            "–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –∫–∞–∫ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫—É—é, —Ç–∞–∫ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å"
        ]
        
        for i, conclusion in enumerate(conclusions, 1):
            conspect += f"{i}. {conclusion}\n"
        
        conspect += f"\nüìå *–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:* –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.\n\n"
        conspect += f"üîç *–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ Google*\n"
        conspect += f"ü§ñ *–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ @Konspekt_help_bot*\n"
        conspect += f"‚è± *–í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è:* {datetime.now().strftime('%H:%M')}"
        
        return conspect
    
    def _generate_extended(self, topic, results):
        """–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô - –Ω–µ –æ–±—Ä—ã–≤–∞–µ—Ç—Å—è)"""
        items = results.get("items", [])
        topic_info = results.get("topic_info", {})
        
        # –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        conspect_parts = []
        
        # –ß–∞—Å—Ç—å 1: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –≤–≤–µ–¥–µ–Ω–∏–µ
        part1 = f"üìñ *–ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï: {topic.upper()}*\n\n"
        part1 += "=" * 50 + "\n"
        part1 += "–ß–ê–°–¢–¨ 1: –í–í–ï–î–ï–ù–ò–ï –ò –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø\n"
        part1 += "=" * 50 + "\n\n"
        
        part1 += f"**–¢–ï–ú–ê –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:** {topic}\n\n"
        part1 += "**–ê–ö–¢–£–ê–õ–¨–ù–û–°–¢–¨ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n"
        part1 += f"–ò–∑—É—á–µ–Ω–∏–µ —Ç–µ–º—ã '{topic}' –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –Ω–∞—É—á–Ω—ã–π –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–µ—Å. "
        part1 += "–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å—é —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –∏ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ–Ω–¥–µ–Ω—Ü–∏–π.\n\n"
        
        part1 += "**–ú–ï–¢–û–î–û–õ–û–ì–ò–ß–ï–°–ö–ò–ï –û–°–ù–û–í–´:**\n"
        part1 += "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ, —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–æ–≤. "
        part1 += f"–ë—ã–ª–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {results.get('total_filtered', 0)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, "
        part1 += "–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏.\n\n"
        
        conspect_parts.append(part1)
        
        # –ß–∞—Å—Ç—å 2: –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        part2 = "=" * 50 + "\n"
        part2 += "–ß–ê–°–¢–¨ 2: –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –û–ë–ó–û–† –ò–°–¢–û–ß–ù–ò–ö–û–í\n"
        part2 += "=" * 50 + "\n\n"
        
        if items:
            part2 += "**–û–ë–ó–û–† –ö–õ–Æ–ß–ï–í–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í:**\n\n"
            
            for i, item in enumerate(items, 1):
                title = item.get("title", f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i}")
                text = item.get("snippet", "")
                source = item.get("source", "–∏—Å—Ç–æ—á–Ω–∏–∫")
                
                part2 += f"**{i}. {title}**\n"
                part2 += f"*–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:* {text}\n"
                part2 += f"*–ò—Å—Ç–æ—á–Ω–∏–∫:* {source}\n"
                part2 += "*–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞:* –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∫–∞—á–µ—Å—Ç–≤–∞ "
                part2 += "–∏ –≤–Ω–æ—Å–∏—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–º—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n\n"
        else:
            part2 += "**–û–°–û–ë–ï–ù–ù–û–°–¢–ò –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ô –ë–ê–ó–´:**\n"
            part2 += "–ü—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã—è–≤–∏–ª –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö "
            part2 += "–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Å–≤–µ—â–µ–Ω–∏—è —Ç–µ–º—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n\n"
        
        conspect_parts.append(part2)
        
        # –ß–∞—Å—Ç—å 3: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        part3 = "=" * 50 + "\n"
        part3 += "–ß–ê–°–¢–¨ 3: –°–¢–†–£–ö–¢–£–†–ù–´–ô –ò –ö–û–ù–¶–ï–ü–¢–£–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó\n"
        part3 += "=" * 50 + "\n\n"
        
        part3 += "**–ö–û–ù–¶–ï–ü–¢–£–ê–õ–¨–ù–´–ô –ê–ü–ü–ê–†–ê–¢ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n\n"
        
        keywords = results.get("keywords", [])
        if keywords:
            for i, keyword in enumerate(keywords[:8], 1):
                part3 += f"{i}. **{keyword.capitalize()}** ‚Äî –∫–ª—é—á–µ–≤–æ–µ –ø–æ–Ω—è—Ç–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, "
                part3 += "—Ç—Ä–µ–±—É—é—â–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –≤ —Ä–∞–º–∫–∞—Ö –∏–∑—É—á–∞–µ–º–æ–π —Ç–µ–º–∞—Ç–∏–∫–∏.\n\n"
        else:
            concepts = [
                "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                "–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–ø–ø–∞—Ä–∞—Ç",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å",
                "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å",
                "–û—Ü–µ–Ω–æ—á–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏",
                "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è"
            ]
            
            for i, concept in enumerate(concepts, 1):
                part3 += f"{i}. **{concept}** ‚Äî –≤–∞–∂–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, "
                part3 += "–æ–ø—Ä–µ–¥–µ–ª—è—é—â–∏–π –µ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ.\n\n"
        
        conspect_parts.append(part3)
        
        # –ß–∞—Å—Ç—å 4: –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        part4 = "=" * 50 + "\n"
        part4 += "–ß–ê–°–¢–¨ 4: –í–´–í–û–î–´, –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –ü–ï–†–°–ü–ï–ö–¢–ò–í–´\n"
        part4 += "=" * 50 + "\n\n"
        
        part4 += "**–û–°–ù–û–í–ù–´–ï –í–´–í–û–î–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:**\n\n"
        
        conclusions = [
            f"–¢–µ–º–∞ '{topic}' –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É, —Ç—Ä–µ–±—É—é—â—É—é –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è",
            "–ü—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã—è–≤–∏–ª –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–π –∏–∑—É—á–µ–Ω–∏—è",
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–∞–∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ç—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è",
            "–í—ã—è–≤–ª–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã, —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç —Ç–µ–º—ã",
            "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –∏–∑—É—á–∞–µ–º–æ–π –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏–∫–∏"
        ]
        
        for i, conclusion in enumerate(conclusions, 1):
            part4 += f"{i}. {conclusion}\n"
        
        part4 += f"\n**–ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**\n\n"
        
        recommendations = [
            "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ —Ç–µ–º—ã —Å –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤",
            "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤",
            "–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –ø–æ —Ç–µ–º–µ",
            "–û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–æ–≤—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π",
            "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤"
        ]
        
        for i, recommendation in enumerate(recommendations, 1):
            part4 += f"{i}. {recommendation}\n"
        
        part4 += f"\n**–ü–ï–†–°–ü–ï–ö–¢–ò–í–ù–´–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø:**\n\n"
        part4 += "‚Ä¢ –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Ç–µ–º—ã\n"
        part4 += "‚Ä¢ –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –æ–ø—ã—Ç–∞\n"
        part4 += "‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –∏–∑—É—á–µ–Ω–∏—è\n"
        part4 += "‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤\n"
        part4 += "‚Ä¢ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∫–µ–π—Å–æ–≤ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è\n"
        
        # –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        part4 += f"\n" + "=" * 50 + "\n"
        part4 += "–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø\n"
        part4 += "=" * 50 + "\n\n"
        
        part4 += f"‚Ä¢ **–î–∞—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:** {datetime.now().strftime('%d.%m.%Y')}\n"
        part4 += f"‚Ä¢ **–í—Ä–µ–º—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è:** {datetime.now().strftime('%H:%M')}\n"
        part4 += f"‚Ä¢ **–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–µ–º—ã:** {topic_info.get('category', '–æ–±—â–∞—è —Ç–µ–º–∞')}\n"
        part4 += f"‚Ä¢ **–°–ª–æ–∂–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:** {topic_info.get('complexity', '–±–∞–∑–æ–≤–∞—è')}\n"
        part4 += f"‚Ä¢ **–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** {results.get('total_filtered', 0)}\n"
        part4 += f"‚Ä¢ **–ú–µ—Ç–æ–¥ –æ—Ç–±–æ—Ä–∞:** —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤—É\n"
        part4 += f"‚Ä¢ **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:** Google Custom Search API —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π\n"
        part4 += f"‚Ä¢ **–°–∏—Å—Ç–µ–º–∞:** @Konspekt_help_bot\n\n"
        
        part4 += "¬© –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ. –î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º."
        
        conspect_parts.append(part4)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
        full_conspect = "\n".join(conspect_parts)
        return full_conspect

# ==================== TELEGRAM BOT ====================
class TelegramBot:
    def __init__(self):
        if not TELEGRAM_TOKEN:
            raise ValueError("TELEGRAM_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        self.token = TELEGRAM_TOKEN
        self.bot_url = f"https://api.telegram.org/bot{self.token}"
        self.generator = ConspectGenerator()
        
        if RENDER_EXTERNAL_URL:
            self._setup_webhook()
        
        logger.info("‚úÖ Telegram –±–æ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –≥–æ—Ç–æ–≤")
    
    def _setup_webhook(self):
        webhook_url = f"{RENDER_EXTERNAL_URL}/webhook"
        try:
            response = requests.post(
                f"{self.bot_url}/setWebhook",
                json={"url": webhook_url},
                timeout=10
            )
            if response.json().get("ok"):
                logger.info(f"‚úÖ –í–µ–±—Ö—É–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {webhook_url}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ–±—Ö—É–∫–∞: {e}")
    
    def process_message(self, chat_id, text):
        text = text.strip()
        self._update_stats(chat_id)
        
        if text.startswith("/"):
            if text == "/start":
                return self._send_welcome(chat_id)
            elif text == "/help":
                return self._send_help(chat_id)
            elif text == "/stats":
                return self._send_stats(chat_id)
            else:
                return self._send_message(chat_id, "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help")
        
        if text in ["1", "2", "3"]:
            return self._handle_volume(chat_id, text)
        
        return self._handle_topic(chat_id, text)
    
    def _send_welcome(self, chat_id):
        welcome = (
            "üëã *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —É–ª—É—á—à–µ–Ω–Ω—ã–π Konspekt Helper Bot!*\n\n"
            "ü§ñ *–¢–µ–ø–µ—Ä—å —Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞!*\n\n"
            "üîÑ *–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:*\n"
            "‚Ä¢ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–π\n"
            "‚Ä¢ –û—Ç–±–æ—Ä —Ç–æ–ª—å–∫–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            "‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n"
            "‚Ä¢ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n\n"
            "üìä *–û–±—ä–µ–º—ã –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤:*\n"
            "‚Ä¢ *1* ‚Äî –ö—Ä–∞—Ç–∫–∏–π (–∫–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã)\n"
            "‚Ä¢ *2* ‚Äî –ü–æ–¥—Ä–æ–±–Ω—ã–π (—Å –∞–Ω–∞–ª–∏–∑–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)\n"
            "‚Ä¢ *3* ‚Äî –†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π (–ø–æ–ª–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ)\n\n"
            "üéØ *–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–º—É –¥–ª—è –Ω–∞—á–∞–ª–∞!*"
        )
        return self._send_message(chat_id, welcome)
    
    def _send_help(self, chat_id):
        help_text = (
            "üìö *–°–ü–†–ê–í–ö–ê –ü–û –£–õ–£–ß–®–ï–ù–ù–û–ú–£ –ë–û–¢–£*\n\n"
            "*–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:*\n"
            "‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è\n"
            "‚Ä¢ –û—Ç–±–∏—Ä–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏\n"
            "‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å—É\n"
            "‚Ä¢ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–µ–º—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n\n"
            "*–ü—Ä–∏–º–µ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:*\n"
            "‚Ä¢ '–†–∞–∑–≤–∏—Ç–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞'\n"
            "‚Ä¢ '–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –∏–Ω—Ñ–ª—è—Ü–∏–∏'\n"
            "‚Ä¢ '–ù–∞—É—á–Ω—ã–µ –æ—Ç–∫—Ä—ã—Ç–∏—è –≤ –º–µ–¥–∏—Ü–∏–Ω–µ'\n"
            "‚Ä¢ '–¶–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è'\n\n"
            "*–ò–∑–±–µ–≥–∞–π—Ç–µ:*\n"
            "‚Ä¢ –í–æ–ø—Ä–æ—Å–æ–≤ (–ö–∞–∫...? –ü–æ—á–µ–º—É...?)\n"
            "‚Ä¢ –û–±—Å—É–∂–¥–µ–Ω–∏–π –∏ —Ñ–æ—Ä—É–º–æ–≤\n"
            "‚Ä¢ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"
        )
        return self._send_message(chat_id, help_text)
    
    def _send_stats(self, chat_id):
        stat_text = (
            f"üìä *–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–û–¢–ê*\n\n"
            f"üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['total_users']}\n"
            f"üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: {stats['total_messages']}\n"
            f"üìÑ –ö–æ–Ω—Å–ø–µ–∫—Ç–æ–≤: {stats['conspects_created']}\n"
            f"üîç –ü–æ–∏—Å–∫–æ–≤ Google: {stats['google_searches']}\n"
            f"‚è± –ó–∞–ø—É—â–µ–Ω: {stats['start_time'][:10]}\n\n"
            f"üåê –†–µ–∂–∏–º: –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞"
        )
        return self._send_message(chat_id, stat_text)
    
    def _handle_topic(self, chat_id, topic):
        user_id = str(chat_id)
        if user_id not in stats["user_states"]:
            stats["user_states"][user_id] = {}
        
        stats["user_states"][user_id]["pending_topic"] = topic
        
        response = (
            f"üéØ *–¢–ï–ú–ê: {topic}*\n\n"
            f"‚úÖ –ù–∞—á–∏–Ω–∞—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫...\n\n"
            f"üîÑ *–ë—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã:*\n"
            f"‚Ä¢ –í–æ–ø—Ä–æ—Å—ã –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è\n"
            f"‚Ä¢ –ù–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç\n"
            f"‚Ä¢ –ù–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏\n\n"
            f"üìä *–í–´–ë–ï–†–ò–¢–ï –û–ë–™–ï–ú:*\n\n"
            f"1Ô∏è‚É£ *–ö–†–ê–¢–ö–ò–ô* ‚Äî –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–∑–∏—Å—ã\n"
            f"2Ô∏è‚É£ *–ü–û–î–†–û–ë–ù–´–ô* ‚Äî —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n"
            f"3Ô∏è‚É£ *–†–ê–ó–í–ï–†–ù–£–¢–´–ô* ‚Äî –ø–æ–ª–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ\n\n"
            f"üî¢ *–û—Ç–ø—Ä–∞–≤—å—Ç–µ 1, 2 –∏–ª–∏ 3*"
        )
        return self._send_message(chat_id, response)
    
    def _handle_volume(self, chat_id, volume_choice):
        user_id = str(chat_id)
        user_state = stats["user_states"].get(user_id, {})
        topic = user_state.get("pending_topic", "")
        
        if not topic:
            return self._send_message(chat_id, "‚ùå –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–º—É")
        
        volume_map = {"1": "short", "2": "detailed", "3": "extended"}
        volume = volume_map.get(volume_choice, "short")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        self._send_message(
            chat_id,
            f"üîç *–í–´–ü–û–õ–ù–Ø–Æ –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–´–ô –ü–û–ò–°–ö...*\n\n"
            f"üìå –¢–µ–º–∞: {topic}\n"
            f"üìä –û–±—ä–µ–º: {volume_choice}/3\n"
            f"üîÑ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –ê–ö–¢–ò–í–ù–ê\n\n"
            f"‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏ –æ—Ç–±–∏—Ä–∞—é –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏..."
        )
        
        try:
            conspect = self.generator.generate(topic, volume)
            stats["conspects_created"] += 1
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–ø–µ–∫—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            self._send_conspect_safely(chat_id, conspect)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            final_msg = (
                f"‚úÖ *–ö–û–ù–°–ü–ï–ö–¢ –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù!*\n\n"
                f"üìå –¢–µ–º–∞: {topic}\n"
                f"üìä –û–±—ä–µ–º: {volume_choice}/3\n"
                f"üîç –ü–æ–∏—Å–∫–æ–≤: {stats['google_searches']}\n"
                f"üîÑ –†–µ–∂–∏–º: –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π\n\n"
                f"üîÑ –î—Ä—É–≥–æ–π –æ–±—ä–µ–º? –û—Ç–ø—Ä–∞–≤—å—Ç–µ 1, 2 –∏–ª–∏ 3\n"
                f"üéØ –ù–æ–≤–∞—è —Ç–µ–º–∞? –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –µ—ë!"
            )
            return self._send_message(chat_id, final_msg)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∞: {e}")
            return self._send_message(
                chat_id,
                f"‚ùå *–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞*\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–∑–∂–µ.\n\n"
                f"–û—à–∏–±–∫–∞: {str(e)[:100]}"
            )
    
    def _send_conspect_safely(self, chat_id, conspect):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Å–ø–µ–∫—Ç, —Ä–∞–∑–±–∏–≤–∞—è –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"""
        max_length = 4000  # Telegram limit with some buffer
        
        if len(conspect) <= max_length:
            self._send_message(chat_id, conspect)
            return
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–∏
        parts = self._split_conspect_logically(conspect)
        
        for i, part in enumerate(parts, 1):
            if i > 1:
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
                continuation = f"üìñ *–ü–†–û–î–û–õ–ñ–ï–ù–ò–ï ({i}/{len(parts)})*\n\n"
                part = continuation + part
            
            if len(part) > max_length:
                # –ï—Å–ª–∏ —á–∞—Å—Ç—å –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
                sub_parts = self._split_by_paragraphs(part, max_length)
                for sub_part in sub_parts:
                    self._send_message(chat_id, sub_part)
                    import time
                    time.sleep(0.3)
            else:
                self._send_message(chat_id, part)
                import time
                time.sleep(0.3)
    
    def _split_conspect_logically(self, conspect):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–ø–µ–∫—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–∏"""
        parts = []
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –±–æ–ª—å—à–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
        sections = re.split(r'(=+\n[^=]+\n=+)', conspect)
        
        current_part = ""
        for section in sections:
            if not section.strip():
                continue
            
            # –ï—Å–ª–∏ —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞
            if re.match(r'=+\n[^=]+\n=+', section):
                if current_part and len(current_part) > 1000:
                    parts.append(current_part.strip())
                    current_part = section + "\n\n"
                else:
                    current_part += section + "\n\n"
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏ —Ç–µ–∫—É—â–∞—è —á–∞—Å—Ç—å –ª–∏–º–∏—Ç
                if len(current_part + section) > 3500:
                    parts.append(current_part.strip())
                    current_part = section
                else:
                    current_part += section
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å
        if current_part.strip():
            parts.append(current_part.strip())
        
        return parts
    
    def _split_by_paragraphs(self, text, max_length):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –∞–±–∑–∞—Ü–∞–º"""
        paragraphs = text.split('\n\n')
        parts = []
        current_part = ""
        
        for paragraph in paragraphs:
            if len(current_part + paragraph) > max_length and current_part:
                parts.append(current_part.strip())
                current_part = paragraph
            else:
                if current_part:
                    current_part += "\n\n" + paragraph
                else:
                    current_part = paragraph
        
        if current_part.strip():
            parts.append(current_part.strip())
        
        return parts
    
    def _update_stats(self, chat_id):
        user_id = str(chat_id)
        
        if user_id not in stats["user_states"]:
            stats["total_users"] += 1
            stats["user_states"][user_id] = {
                "first_seen": datetime.now().isoformat(),
                "message_count": 0
            }
        
        stats["user_states"][user_id]["last_seen"] = datetime.now().isoformat()
        stats["user_states"][user_id]["message_count"] += 1
        stats["total_messages"] += 1
    
    def _send_message(self, chat_id, text):
        try:
            response = requests.post(
                f"{self.bot_url}/sendMessage",
                json={
                    "chat_id": chat_id,
                    "text": text,
                    "parse_mode": "Markdown",
                    "disable_web_page_preview": True
                },
                timeout=10
            )
            return response.json().get("ok", False)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            return False

# ==================== HTTP –°–ï–†–í–ï–† ====================
class BotHTTPServer(BaseHTTPRequestHandler):
    def do_GET(self):
        path = self.path.split('?')[0]
        
        if path == "/":
            self._send_html(INDEX_HTML)
        elif path == "/health":
            self._send_json({"status": "ok", "time": datetime.now().isoformat()})
        elif path == "/stats":
            self._send_json(stats)
        else:
            self.send_response(404)
            self.end_headers()
    
    def do_POST(self):
        if self.path == "/webhook":
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length:
                try:
                    data = self.rfile.read(content_length)
                    update = json.loads(data.decode('utf-8'))
                    
                    threading.Thread(
                        target=self._handle_update,
                        args=(update,),
                        daemon=True
                    ).start()
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ–±—Ö—É–∫–∞: {e}")
            
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b'OK')
        else:
            self.send_response(404)
            self.end_headers()
    
    def _handle_update(self, update):
        try:
            if "message" in update and "text" in update["message"]:
                chat_id = update["message"]["chat"]["id"]
                text = update["message"]["text"]
                
                bot = TelegramBot()
                bot.process_message(chat_id, text)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    
    def _send_html(self, content):
        self.send_response(200)
        self.send_header('Content-Type', 'text/html; charset=utf-8')
        self.end_headers()
        self.wfile.write(content.encode('utf-8'))
    
    def _send_json(self, data):
        self.send_response(200)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.end_headers()
        self.wfile.write(json.dumps(data, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def log_message(self, format, *args):
        pass

INDEX_HTML = """<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ü§ñ Konspekt Helper Bot</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
        .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .status { color: green; font-weight: bold; padding: 10px; background: #e8f5e8; border-radius: 5px; }
        .feature { background: #f0f8ff; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #0088cc; }
        .btn { display: inline-block; background: #0088cc; color: white; padding: 10px 20px; border-radius: 5px; text-decoration: none; margin: 5px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ü§ñ Konspekt Helper Bot</h1>
        <p class="status">‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π</p>
        <p>Telegram –±–æ—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞</p>
        
        <div class="feature">
            <h3>üîÑ –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è</h3>
            <p>–ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç:</p>
            <ul>
                <li>‚ùå –í–æ–ø—Ä–æ—Å—ã –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è</li>
                <li>‚ùå –ù–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç</li>
                <li>‚ùå –ù–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏</li>
                <li>‚úÖ –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã</li>
            </ul>
        </div>
        
        <h3>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã:</h3>
        <div id="stats">–ó–∞–≥—Ä—É–∑–∫–∞...</div>
        
        <h3>üîó –ë—ã—Å—Ç—Ä—ã–µ —Å—Å—ã–ª–∫–∏:</h3>
        <div>
            <a href="https://t.me/Konspekt_help_bot" class="btn" target="_blank">ü§ñ –û—Ç–∫—Ä—ã—Ç—å –±–æ—Ç–∞</a>
            <a href="/stats" class="btn">üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</a>
            <a href="/health" class="btn">‚ù§Ô∏è Health Check</a>
        </div>
        
        <h3>üéØ –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç:</h3>
        <ol>
            <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ–º—ã –≤–º–µ—Å—Ç–æ –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤</li>
            <li>–ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ —Ç–∏–ø–∞ "–ö–∞–∫...?" –∏–ª–∏ "–ü–æ—á–µ–º—É...?"</li>
            <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –ø–æ–Ω—è—Ç–∏—è</li>
            <li>–ü—Ä–∏–º–µ—Ä—ã —Ö–æ—Ä–æ—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:
                <ul>
                    <li>–†–∞–∑–≤–∏—Ç–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞</li>
                    <li>–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –∏–Ω—Ñ–ª—è—Ü–∏–∏</li>
                    <li>–¶–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è</li>
                </ul>
            </li>
        </ol>
        
        <p style="color: #666; font-size: 14px; margin-top: 30px;">
            –û–±–Ω–æ–≤–ª–µ–Ω–æ: <span id="time"></span>
        </p>
    </div>
    
    <script>
        async function loadStats() {
            try {
                const response = await fetch('/stats');
                const data = await response.json();
                
                document.getElementById('stats').innerHTML = `
                    <p>üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: ${data.total_users || 0}</p>
                    <p>üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: ${data.total_messages || 0}</p>
                    <p>üìÑ –ö–æ–Ω—Å–ø–µ–∫—Ç–æ–≤: ${data.conspects_created || 0}</p>
                    <p>üîç –ü–æ–∏—Å–∫–æ–≤ Google: ${data.google_searches || 0}</p>
                `;
                
                document.getElementById('time').textContent = new Date().toLocaleTimeString();
            } catch (error) {
                document.getElementById('stats').innerHTML = '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏';
            }
        }
        
        loadStats();
        setInterval(loadStats, 5000);
    </script>
</body>
</html>
"""

# ==================== –ó–ê–ü–£–°–ö ====================
def main():
    logger.info("=" * 60)
    logger.info("üöÄ –ó–ê–ü–£–°–ö KONSPEKT BOT –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô")
    logger.info("=" * 60)
    logger.info(f"üåê URL: {RENDER_EXTERNAL_URL}")
    logger.info(f"üö™ –ü–æ—Ä—Ç: {PORT}")
    logger.info("‚úÖ –í—Å–µ —Ç—Ä–∏ –æ–±—ä–µ–º–∞ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    logger.info("üîÑ –†–µ–∂–∏–º: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
    logger.info("=" * 60)
    
    server = HTTPServer(('', PORT), BotHTTPServer)
    logger.info(f"‚úÖ HTTP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()
